<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interview Preparation Tool</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.9;
        }

        .header-nav {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }

        .header-nav-btn {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: 2px solid white;
            padding: 10px 20px;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s;
            font-size: 1em;
        }

        .header-nav-btn:hover {
            background: white;
            color: #667eea;
        }

        .header-nav-btn.active {
            background: white;
            color: #667eea;
        }

        .main-content {
            display: flex;
            min-height: 600px;
        }

        .sidebar {
            width: 300px;
            background: #f8f9fa;
            border-right: 2px solid #e9ecef;
            padding: 20px;
            overflow-y: auto;
            max-height: 600px;
            transition: all 0.3s;
        }

        .sidebar.hidden {
            width: 0;
            padding: 0;
            overflow: hidden;
            border-right: none;
        }

        .category-filter {
            margin-bottom: 20px;
        }

        .category-filter-title {
            font-size: 0.9em;
            color: #666;
            margin-bottom: 10px;
            font-weight: bold;
        }

        .category-chips {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-bottom: 20px;
        }

        .category-chip {
            background: white;
            color: #667eea;
            border: 2px solid #667eea;
            padding: 6px 12px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 0.85em;
            transition: all 0.3s;
            font-weight: 500;
        }

        .category-chip:hover {
            background: #e7e9ff;
        }

        .category-chip.active {
            background: #667eea;
            color: white;
        }

        .question-counter {
            background: #f8f9fa;
            padding: 10px 15px;
            border-radius: 8px;
            margin-bottom: 15px;
            text-align: center;
            font-size: 0.9em;
            color: #666;
        }

        .question-counter strong {
            color: #667eea;
            font-size: 1.2em;
        }

        .question-list {
            padding: 0;
        }

        .question-item {
            padding: 12px 15px;
            margin: 8px 0;
            background: white;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.3s;
            border-left: 3px solid transparent;
            display: flex;
            align-items: flex-start;
            gap: 10px;
        }

        .question-number {
            background: #667eea;
            color: white;
            min-width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            font-size: 0.85em;
            flex-shrink: 0;
        }

        .question-text {
            flex: 1;
            font-size: 0.9em;
            line-height: 1.4;
        }

        .question-category-tag {
            font-size: 0.75em;
            color: #667eea;
            opacity: 0.7;
            margin-top: 4px;
        }

        .question-item:hover {
            background: #e7e9ff;
            border-left-color: #667eea;
            transform: translateX(5px);
        }

        .question-item.active {
            background: #667eea;
            color: white;
            border-left-color: #764ba2;
        }

        .question-item.active .question-number {
            background: #764ba2;
        }

        .question-item.active .question-category-tag {
            color: white;
            opacity: 0.9;
        }

        .question-practice-info {
            display: flex;
            gap: 8px;
            margin-top: 6px;
            font-size: 0.7em;
        }

        .practice-mini-badge {
            background: #e7e9ff;
            color: #667eea;
            padding: 2px 8px;
            border-radius: 10px;
            font-weight: 600;
        }

        .question-item.active .practice-mini-badge {
            background: rgba(255, 255, 255, 0.3);
            color: white;
        }

        .practice-mini-badge.zero {
            background: #ffe7e7;
            color: #dc3545;
        }

        .question-item.active .practice-mini-badge.zero {
            background: rgba(220, 53, 69, 0.3);
            color: white;
        }

        .sidebar-toggle {
            position: fixed;
            left: 20px;
            top: 50%;
            transform: translateY(-50%);
            background: #667eea;
            color: white;
            border: none;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            cursor: pointer;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
            z-index: 100;
            transition: all 0.3s;
            display: none;
            align-items: center;
            justify-content: center;
            font-size: 1.2em;
        }

        .sidebar-toggle.visible {
            display: flex;
        }

        .sidebar-toggle:hover {
            background: #5568d3;
            transform: translateY(-50%) scale(1.1);
        }

        .content-area {
            flex: 1;
            padding: 40px;
            overflow-y: auto;
            max-height: 600px;
        }

        .question-header {
            margin-bottom: 30px;
        }

        .question-title {
            font-size: 1.8em;
            color: #333;
            margin-bottom: 10px;
        }

        .question-category-badge {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 0.9em;
        }

        .answer-section {
            margin-bottom: 30px;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            overflow: hidden;
        }

        .answer-header {
            background: #f8f9fa;
            padding: 15px 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            cursor: pointer;
            transition: background 0.3s;
        }

        .answer-header:hover {
            background: #e9ecef;
        }

        .answer-header h3 {
            color: #333;
            font-size: 1.2em;
        }

        .answer-controls {
            display: flex;
            gap: 10px;
            align-items: center;
        }

        .toggle-btn {
            background: #667eea;
            color: white;
            border: none;
            padding: 8px 15px;
            border-radius: 5px;
            cursor: pointer;
            transition: all 0.3s;
            font-size: 0.9em;
        }

        .toggle-btn:hover {
            background: #5568d3;
            transform: scale(1.05);
        }

        .counter {
            display: flex;
            align-items: center;
            gap: 5px;
            background: white;
            padding: 3px 8px;
            border-radius: 5px;
            border: 1px solid #dee2e6;
            font-size: 0.75em;
            opacity: 0.8;
        }

        .counter-value {
            font-weight: bold;
            color: #667eea;
            min-width: 20px;
            text-align: center;
            font-size: 0.9em;
        }

        .counter-btn {
            background: #28a745;
            color: white;
            border: none;
            width: 18px;
            height: 18px;
            border-radius: 50%;
            cursor: pointer;
            font-size: 0.75em;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .counter-btn:hover {
            background: #218838;
            transform: scale(1.1);
            opacity: 1;
        }

        .answer-content {
            padding: 20px;
            background: white;
            display: none;
            line-height: 1.8;
            color: #555;
        }

        .answer-content.visible {
            display: block;
        }

        .answer-content ul {
            margin-left: 20px;
            margin-top: 10px;
        }

        .answer-content li {
            margin: 8px 0;
        }

        .key-concepts {
            margin-top: 30px;
        }

        .key-concepts h3 {
            margin-bottom: 15px;
            color: #333;
        }

        .concept-buttons {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }

        .concept-btn {
            background: #764ba2;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s;
            font-size: 1em;
        }

        .concept-btn:hover {
            background: #5d3a82;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(118, 75, 162, 0.4);
        }

        .navigation {
            display: flex;
            justify-content: space-between;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e9ecef;
        }

        .nav-btn {
            background: #667eea;
            color: white;
            border: none;
            padding: 12px 30px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1em;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .nav-btn:hover:not(:disabled) {
            background: #5568d3;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .nav-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
        }

        /* Modal Styles */
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.7);
            animation: fadeIn 0.3s;
        }

        .modal.active {
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .modal-content {
            background: white;
            padding: 30px;
            border-radius: 15px;
            max-width: 600px;
            max-height: 80vh;
            overflow-y: auto;
            animation: slideIn 0.3s;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
        }

        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 2px solid #e9ecef;
        }

        .modal-header h2 {
            color: #764ba2;
        }

        .close-btn {
            background: #dc3545;
            color: white;
            border: none;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            cursor: pointer;
            font-size: 1.2em;
            transition: all 0.3s;
        }

        .close-btn:hover {
            background: #c82333;
            transform: rotate(90deg);
        }

        .modal-body {
            line-height: 1.8;
            color: #555;
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        @keyframes slideIn {
            from {
                transform: translateY(-50px);
                opacity: 0;
            }
            to {
                transform: translateY(0);
                opacity: 1;
            }
        }

        /* Practice Overview Styles */
        .practice-overview {
            display: none;
        }

        .practice-overview.active {
            display: block;
        }

        .overview-stats {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            display: flex;
            gap: 20px;
            flex-wrap: wrap;
        }

        .stat-card {
            background: white;
            padding: 15px 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
            flex: 1;
            min-width: 150px;
        }

        .stat-card h4 {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 5px;
        }

        .stat-card .stat-value {
            font-size: 2em;
            font-weight: bold;
            color: #667eea;
        }

        .overview-table {
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        .overview-category {
            margin-bottom: 20px;
        }

        .overview-category-header {
            background: #667eea;
            color: white;
            padding: 15px 20px;
            font-weight: bold;
            font-size: 1.1em;
        }

        .overview-question {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 15px 20px;
            border-bottom: 1px solid #e9ecef;
            cursor: pointer;
            transition: all 0.3s;
        }

        .overview-question:hover {
            background: #f8f9fa;
            padding-left: 25px;
        }

        .overview-question:last-child {
            border-bottom: none;
        }

        .overview-question-text {
            flex: 1;
            color: #333;
        }

        .overview-practice-count {
            display: flex;
            gap: 15px;
            align-items: center;
            font-size: 0.9em;
        }

        .practice-badge {
            background: #e7e9ff;
            color: #667eea;
            padding: 5px 12px;
            border-radius: 15px;
            font-weight: bold;
            min-width: 60px;
            text-align: center;
        }

        .practice-badge.low {
            background: #ffe7e7;
            color: #dc3545;
        }

        .practice-badge.medium {
            background: #fff3cd;
            color: #ffc107;
        }

        .practice-badge.high {
            background: #d4edda;
            color: #28a745;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            body {
                padding: 0;
            }

            .container {
                border-radius: 0;
            }

            .header h1 {
                font-size: 1.5em;
            }

            .header p {
                font-size: 0.9em;
            }

            .header-nav {
                flex-wrap: wrap;
            }

            .header-nav-btn {
                padding: 8px 15px;
                font-size: 0.9em;
            }

            .main-content {
                flex-direction: column;
            }

            .sidebar {
                width: 100%;
                max-height: 400px;
                border-right: none;
                border-bottom: 2px solid #e9ecef;
            }

            .sidebar.hidden {
                max-height: 0;
                padding: 0;
            }

            .sidebar-toggle {
                left: 10px;
                top: auto;
                bottom: 20px;
                transform: none;
            }

            .sidebar-toggle:hover {
                transform: scale(1.1);
            }

            .content-area {
                padding: 15px;
                max-height: none;
            }

            .question-title {
                font-size: 1.3em;
            }

            .answer-header {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }

            .answer-controls {
                width: 100%;
                justify-content: space-between;
            }

            .concept-buttons {
                flex-direction: column;
            }

            .concept-btn {
                width: 100%;
            }

            .navigation {
                flex-direction: column;
                gap: 10px;
            }

            .nav-btn {
                width: 100%;
                justify-content: center;
            }

            .modal-content {
                margin: 20px;
                max-width: calc(100% - 40px);
                padding: 20px;
            }

            .overview-stats {
                flex-direction: column;
            }

            .stat-card {
                min-width: 100%;
            }

            .overview-question {
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }

            .overview-practice-count {
                width: 100%;
                justify-content: space-between;
            }
        }

        @media (max-width: 480px) {
            .header h1 {
                font-size: 1.2em;
            }

            .header p {
                font-size: 0.85em;
            }

            .sidebar {
                padding: 10px;
            }

            .content-area {
                padding: 10px;
            }

            .answer-header h3 {
                font-size: 1em;
            }

            .toggle-btn {
                padding: 6px 12px;
                font-size: 0.85em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ðŸŽ¯ Interview Preparation Tool</h1>
            <p>Master your interview with structured practice and key concepts</p>
            <div class="header-nav">
                <button class="header-nav-btn active" onclick="switchView('questions')">ðŸ“š Questions</button>
                <button class="header-nav-btn" onclick="switchView('overview')">ðŸ“Š Practice Overview</button>
            </div>
        </div>

        <div class="main-content" id="questionsView">
            <button class="sidebar-toggle" id="sidebarToggle" onclick="toggleSidebar()">â˜°</button>
            
            <div class="sidebar" id="sidebar">
                <!-- Categories and questions will be dynamically loaded here -->
            </div>

            <div class="content-area" id="contentArea">
                <div class="question-header">
                    <h2 class="question-title" id="questionTitle">Select a question to begin</h2>
                    <span class="question-category-badge" id="categoryBadge"></span>
                </div>

                <div id="questionContent">
                    <!-- Question content will be dynamically loaded here -->
                </div>
            </div>
        </div>

        <div class="practice-overview" id="overviewView">
            <div class="content-area">
                <h2 style="margin-bottom: 20px; color: #333;">ðŸ“Š Practice Overview</h2>
                
                <div class="overview-stats" id="overviewStats">
                    <!-- Stats will be dynamically loaded here -->
                </div>

                <div id="overviewContent">
                    <!-- Overview content will be dynamically loaded here -->
                </div>
            </div>
        </div>
    </div>

    <!-- Modal for Key Concepts -->
    <div class="modal" id="conceptModal">
        <div class="modal-content">
            <div class="modal-header">
                <h2 id="conceptTitle">Key Concept</h2>
                <button class="close-btn" onclick="closeModal()">&times;</button>
            </div>
            <div class="modal-body" id="conceptBody">
                <!-- Concept content will be loaded here -->
            </div>
        </div>
    </div>

    <script>
        // JSON Data
        const interviewData = {
            categories: [
                {
                    id: 1,
                    name: ".NET Core 8+ Backend",
                    questions: [
                        {
                            id: 1,
                            question: "What are the key new features in .NET 8 that you would leverage in a production application?",
                            suggestedAnswer: ".NET 8 brings several production-ready features that I would leverage. First, there's native AOT compilation which significantly reduces startup time and memory footprint, perfect for serverless scenarios. The improved performance includes faster JSON serialization with System.Text.Json and enhanced LINQ operations. For web APIs, there are built-in rate limiting middleware and improved minimal APIs with better parameter binding and validation. The new TimeProvider abstraction makes testing time-dependent code much easier. From my experience with .NET 8 microservices at BIPO, the enhanced observability with OpenTelemetry integration has been invaluable for distributed tracing across our multi-country HR services. The improved container support and reduced image sizes also align well with our Kubernetes deployments.",
                            bulletPoints: [
                                "Native AOT compilation for faster startup and reduced memory usage",
                                "Built-in rate limiting middleware for API protection",
                                "Enhanced minimal APIs with better parameter binding",
                                "TimeProvider abstraction for testable time-dependent code",
                                "Improved JSON serialization performance",
                                "Better OpenTelemetry integration for observability",
                                "Optimized container images with smaller sizes"
                            ],
                            keyConcepts: [
                                {
                                    name: "Native AOT (Ahead-of-Time)",
                                    explanation: "Native AOT compiles your .NET application directly to native machine code before deployment, rather than using Just-In-Time compilation at runtime. This means your app starts much faster and uses less memory because it doesn't need the .NET runtime to compile code on the fly. Think of it like the difference between having a ready-to-eat meal versus having to cook it first - AOT gives you the ready-to-eat version."
                                },
                                {
                                    name: "Rate Limiting Middleware",
                                    explanation: "Rate limiting controls how many requests a client can make to your API within a specific time window. It's like a bouncer at a club who only lets in a certain number of people per hour. This protects your API from being overwhelmed by too many requests, whether from legitimate users or malicious attacks. .NET 8 includes this built-in, so you don't need external libraries."
                                },
                                {
                                    name: "OpenTelemetry Integration",
                                    explanation: "OpenTelemetry is a standard way to collect telemetry data (logs, metrics, traces) from your applications. It's like having a flight recorder in an airplane - it tracks everything that happens so you can understand what went wrong or how to optimize performance. The improved integration in .NET 8 makes it easier to monitor distributed systems where one request might touch multiple services."
                                }
                            ]
                        },
                        {
                            id: 2,
                            question: "Explain minimal APIs in .NET Core 8 and when you would use them over traditional controllers.",
                            suggestedAnswer: "Minimal APIs are a simplified way to create HTTP APIs in .NET with minimal code and dependencies. Instead of using controllers with attributes and conventions, you define endpoints directly in Program.cs using methods like MapGet, MapPost, etc. They're perfect for microservices, simple APIs, or serverless functions where you want reduced ceremony and faster startup times. I would use minimal APIs for lightweight services like health check endpoints, webhook receivers, or simple CRUD operations. However, for complex applications with many endpoints, shared logic, and extensive validation, traditional controllers offer better organization through action filters, model binding, and conventional routing. At BIPO, we used minimal APIs for our internal service-to-service communication endpoints where simplicity and performance were priorities, while customer-facing APIs used controllers for better structure and OpenAPI documentation generation.",
                            bulletPoints: [
                                "Simplified syntax with endpoints defined in Program.cs",
                                "Reduced boilerplate code compared to controllers",
                                "Faster startup time and lower memory footprint",
                                "Ideal for microservices and serverless scenarios",
                                "Use controllers for complex APIs with many endpoints",
                                "Controllers better for shared logic via filters",
                                "Minimal APIs great for simple CRUD or webhooks"
                            ],
                            keyConcepts: [
                                {
                                    name: "Endpoint Definition",
                                    explanation: "In minimal APIs, you define endpoints directly using methods like app.MapGet('/api/users', () => {...}). It's like writing a simple function that responds to a web request, without needing a whole class structure. This makes the code more straightforward for simple scenarios, but can become messy if you have many endpoints."
                                },
                                {
                                    name: "Reduced Ceremony",
                                    explanation: "Ceremony refers to the boilerplate code you need to write - things like class declarations, attributes, inheritance, etc. Minimal APIs reduce this ceremony by letting you write just the essential code. Think of it like texting versus writing a formal letter - sometimes you just need to send a quick message without all the formalities."
                                },
                                {
                                    name: "Action Filters",
                                    explanation: "Action filters in traditional controllers are reusable pieces of code that run before or after your endpoint logic. They're like middleware but specifically for controllers. For example, you might have a filter that validates authentication on every endpoint automatically. Minimal APIs don't have this built-in structure, so you need to handle such cross-cutting concerns differently."
                                }
                            ]
                        },
                        {
                            id: 3,
                            question: "How do you implement and configure middleware in .NET Core 8?",
                            suggestedAnswer: "Middleware in .NET Core is configured in the request pipeline using the WebApplicationBuilder in Program.cs. You add middleware using methods like UseAuthentication, UseAuthorization, or custom middleware with Use, Map, or Run methods. The order matters - middleware executes in the order added for requests and reverse order for responses. To create custom middleware, you implement a class with an InvokeAsync method that takes HttpContext and a RequestDelegate for the next middleware. You can also use inline middleware with app.Use. For example, I've implemented custom middleware for request logging, correlation ID injection, and tenant identification in multi-tenant applications. At Liven Group during our .NET 6 migration, we created middleware to handle legacy authentication tokens during the transition period, allowing both old and new auth mechanisms to coexist.",
                            bulletPoints: [
                                "Configure in Program.cs using WebApplicationBuilder",
                                "Order matters: request flows top-to-bottom, response bottom-to-top",
                                "Built-in middleware: UseAuthentication, UseAuthorization, UseCors",
                                "Custom middleware: class with InvokeAsync(HttpContext, RequestDelegate)",
                                "Inline middleware using app.Use() for simple logic",
                                "Can short-circuit pipeline by not calling next()",
                                "Common uses: logging, authentication, error handling, request modification"
                            ],
                            keyConcepts: [
                                {
                                    name: "Request Pipeline",
                                    explanation: "The request pipeline is like an assembly line for HTTP requests. Each middleware component is a station on that line that can inspect, modify, or respond to the request. The request passes through each middleware in order, and then the response travels back through them in reverse. If any middleware decides to respond early (short-circuit), the request doesn't continue down the line."
                                },
                                {
                                    name: "RequestDelegate",
                                    explanation: "RequestDelegate is a function pointer to the next middleware in the pipeline. When you create custom middleware, you receive this delegate and call it to pass control to the next component. Think of it like a relay race baton - you do your work, then pass the baton (call next()) to continue the race. If you don't call next(), you're ending the race early."
                                },
                                {
                                    name: "Middleware Order",
                                    explanation: "The order you add middleware is critical because it determines what runs first. For example, exception handling should be early so it catches errors from all other middleware. Authentication must come before authorization (you need to know who someone is before checking what they can do). It's like getting dressed - you put on underwear before pants, not after!"
                                }
                            ]
                        },
                        {
                            id: 4,
                            question: "What are the different service lifetimes in .NET Core DI (Singleton, Scoped, Transient) and when would you use each?",
                            suggestedAnswer: "There are three service lifetimes in .NET Core dependency injection. Singleton creates one instance for the entire application lifetime - use this for stateless services like loggers or configuration. Scoped creates one instance per HTTP request or scope - perfect for database contexts, unit of work patterns, or request-specific data. Transient creates a new instance every time it's requested - use for lightweight stateless services. The key rule is never inject a shorter-lived service into a longer-lived one, like injecting a scoped DbContext into a singleton service, as this causes captive dependency issues. At BIPO, we use singleton for our configuration services and caching layers, scoped for Entity Framework DbContext and our unit of work implementations across microservices, and transient for simple data transformation services and validators that have no state.",
                            bulletPoints: [
                                "Singleton: one instance for application lifetime",
                                "Scoped: one instance per HTTP request or scope",
                                "Transient: new instance every time requested",
                                "Singleton use cases: loggers, configuration, caches",
                                "Scoped use cases: DbContext, unit of work, request data",
                                "Transient use cases: lightweight stateless services",
                                "Never inject shorter-lived services into longer-lived ones (captive dependency)"
                            ],
                            keyConcepts: [
                                {
                                    name: "Service Lifetime",
                                    explanation: "Service lifetime determines how long an instance of a service lives and when it gets disposed. Think of it like renting an apartment: Singleton is buying a house (you keep it forever), Scoped is renting monthly (new tenant each month/request), and Transient is a hotel room (new room every night/injection). Choosing the right lifetime affects both performance and correctness."
                                },
                                {
                                    name: "Captive Dependency",
                                    explanation: "A captive dependency occurs when a long-lived service (like Singleton) holds a reference to a short-lived service (like Scoped). It's like keeping last month's milk in your fridge - the milk should have been thrown out, but because it's captured by the fridge, it stays around too long and causes problems. This commonly happens with DbContext being injected into singletons."
                                },
                                {
                                    name: "Scope",
                                    explanation: "A scope is a boundary for service lifetime. In web applications, each HTTP request creates a new scope automatically. All scoped services within that request share the same instance, but a new request gets fresh instances. You can also create manual scopes using IServiceScopeFactory for background tasks or batch operations."
                                }
                            ]
                        },
                        {
                            id: 5,
                            question: "How do you handle configuration in .NET Core 8 (appsettings.json, environment variables, Azure Key Vault)?",
                            suggestedAnswer: "Configuration in .NET Core uses a layered approach where later sources override earlier ones. The default order is appsettings.json, then appsettings.{Environment}.json, then environment variables, then command-line arguments. For sensitive data, I integrate Azure Key Vault using AddAzureKeyVault extension. Environment variables are great for container deployments as they override file-based config without changing code. I use the Options pattern with IOptions or IOptionsSnapshot to inject strongly-typed configuration. For multi-environment setups, I keep common settings in appsettings.json, environment-specific overrides in appsettings.Development.json or appsettings.Production.json, and secrets in Key Vault. At Liven Group, we used AWS Parameter Store similarly, with Terraform managing the infrastructure, and environment variables in Docker containers overriding base configuration for different deployment targets across Australia, Indonesia, and Singapore.",
                            bulletPoints: [
                                "Layered configuration: appsettings.json â†’ environment-specific â†’ env vars â†’ command-line",
                                "Later sources override earlier ones",
                                "Azure Key Vault for sensitive data (connection strings, API keys)",
                                "Environment variables ideal for containerized deployments",
                                "Use Options pattern for strongly-typed configuration",
                                "appsettings.{Environment}.json for environment-specific settings",
                                "Never commit secrets to source control"
                            ],
                            keyConcepts: [
                                {
                                    name: "Configuration Providers",
                                    explanation: "Configuration providers are sources where your app reads settings from. .NET Core checks multiple providers in order and merges them together, with later providers winning conflicts. Think of it like layering transparent sheets - you see through to earlier layers, but if a later layer has something written, it covers what's below. This lets you have base settings in files and override them with environment variables."
                                },
                                {
                                    name: "Environment Variables",
                                    explanation: "Environment variables are key-value pairs set at the operating system or container level. They're perfect for configuration because they don't require changing files or redeploying code. In .NET Core, you use double underscores to represent nested configuration (e.g., ConnectionStrings__DefaultConnection becomes ConnectionStrings:DefaultConnection in your config)."
                                },
                                {
                                    name: "Azure Key Vault",
                                    explanation: "Azure Key Vault is a secure cloud service for storing secrets, keys, and certificates. Instead of putting database passwords in config files, you store them in Key Vault and your application fetches them at startup. It's like having a safe deposit box at a bank instead of hiding money under your mattress - much more secure and you get audit logs of who accessed what."
                                }
                            ]
                        },
                        {
                            id: 6,
                            question: "Explain the Options pattern in .NET Core and how you use it for strongly-typed configuration.",
                            suggestedAnswer: "The Options pattern provides a way to access configuration using strongly-typed classes instead of raw strings. You create a POCO class matching your configuration structure, then register it with services.Configure in Program.cs. You inject it using IOptions, IOptionsSnapshot, or IOptionsMonitor depending on your needs. IOptions is singleton and reads config once at startup. IOptionsSnapshot is scoped and re-reads per request, useful for multi-tenant scenarios. IOptionsMonitor is singleton but reloads when configuration changes. You can also add validation using data annotations or IValidateOptions. This pattern prevents typos, provides IntelliSense, and makes configuration testable. At BIPO, we use this extensively for feature flags, API endpoint configurations, and database connection settings across our microservices, with IOptionsSnapshot for tenant-specific settings that vary per request in our multi-country HR system.",
                            bulletPoints: [
                                "Strongly-typed configuration using POCO classes",
                                "Register with services.Configure<TOptions>()",
                                "IOptions: singleton, reads once at startup",
                                "IOptionsSnapshot: scoped, re-reads per request",
                                "IOptionsMonitor: singleton, reloads on config changes",
                                "Supports validation via data annotations",
                                "Provides IntelliSense and compile-time safety"
                            ],
                            keyConcepts: [
                                {
                                    name: "POCO Configuration Class",
                                    explanation: "POCO stands for Plain Old CLR Object - just a simple class with properties that match your configuration structure. For example, if your appsettings.json has a 'Database' section with 'ConnectionString' and 'Timeout' properties, you create a DatabaseOptions class with those same properties. This gives you type safety and IntelliSense when accessing configuration."
                                },
                                {
                                    name: "IOptions vs IOptionsSnapshot vs IOptionsMonitor",
                                    explanation: "These three interfaces serve different needs. IOptions reads configuration once at startup and never changes - fast but static. IOptionsSnapshot reads fresh configuration for each HTTP request - good for per-request settings like tenant data. IOptionsMonitor watches for configuration file changes and reloads automatically - useful for feature flags that you want to change without restarting the app."
                                },
                                {
                                    name: "Options Validation",
                                    explanation: "You can validate your configuration at startup using data annotations like [Required] or [Range] on your options class. This catches configuration errors early when the app starts, rather than failing at runtime when the config is first used. It's like checking your car has gas before starting a road trip, rather than running out halfway there."
                                }
                            ]
                        },
                        {
                            id: 7,
                            question: "What is the difference between IHostedService and BackgroundService for scheduled tasks?",
                            suggestedAnswer: "IHostedService is the base interface for long-running background tasks in .NET Core, with StartAsync and StopAsync methods. BackgroundService is an abstract base class that implements IHostedService and provides a simpler ExecuteAsync method where you put your background logic. BackgroundService handles the boilerplate of managing cancellation tokens and graceful shutdown. For simple background tasks, use BackgroundService. For more control over startup and shutdown, implement IHostedService directly. I typically use BackgroundService for scheduled jobs like data synchronization or cleanup tasks. At Liven Group, we used BackgroundService for scheduled menu synchronization across restaurant locations and for processing queued orders from SNS. For more complex scenarios requiring precise control over lifecycle, like coordinating multiple services during shutdown, I implement IHostedService directly.",
                            bulletPoints: [
                                "IHostedService: interface with StartAsync and StopAsync",
                                "BackgroundService: abstract class implementing IHostedService",
                                "BackgroundService provides ExecuteAsync method for background logic",
                                "BackgroundService handles cancellation token management",
                                "Use BackgroundService for simple scheduled tasks",
                                "Use IHostedService for complex lifecycle control",
                                "Both registered with AddHostedService()"
                            ],
                            keyConcepts: [
                                {
                                    name: "Hosted Service Lifecycle",
                                    explanation: "Hosted services start when the application starts and stop when it shuts down. StartAsync runs during application startup (before the app accepts requests), and StopAsync runs during shutdown (after the app stops accepting new requests). This makes them perfect for background tasks that should run for the entire application lifetime, like message queue processors or scheduled jobs."
                                },
                                {
                                    name: "ExecuteAsync Method",
                                    explanation: "ExecuteAsync is the main method in BackgroundService where you put your background work. It runs on a background thread and receives a CancellationToken that signals when the application is shutting down. You typically have a loop that runs until cancellation is requested. Think of it like a worker that keeps doing their job until they're told to go home."
                                },
                                {
                                    name: "Graceful Shutdown",
                                    explanation: "Graceful shutdown means giving your background tasks time to finish their current work before the application terminates. When StopAsync is called, you should signal your tasks to stop (via CancellationToken) and wait for them to complete. It's like giving employees a 5-minute warning before closing the office, so they can save their work rather than just cutting the power."
                                }
                            ]
                        },
                        {
                            id: 8,
                            question: "How do you implement health checks in .NET Core for monitoring application status?",
                            suggestedAnswer: "Health checks in .NET Core allow you to expose endpoints that report application health status. You add health checks with builder.Services.AddHealthChecks() and map the endpoint with app.MapHealthChecks. You can create custom health checks by implementing IHealthCheck with a CheckHealthAsync method that returns Healthy, Degraded, or Unhealthy. Common checks include database connectivity, external API availability, and disk space. You can have multiple endpoints like /health/live for liveness (is the app running) and /health/ready for readiness (is the app ready to accept traffic). This is crucial for Kubernetes probes and load balancer health monitoring. At BIPO, we implement health checks for our SQL Server, MongoDB, Redis connections, and external API dependencies. Each microservice exposes both liveness and readiness probes, allowing Kubernetes to automatically restart unhealthy pods and route traffic only to ready instances.",
                            bulletPoints: [
                                "Add with AddHealthChecks() and map with MapHealthChecks()",
                                "Implement IHealthCheck for custom checks",
                                "Returns Healthy, Degraded, or Unhealthy status",
                                "Common checks: database, external APIs, disk space, memory",
                                "Separate endpoints for liveness and readiness",
                                "Integrates with Kubernetes probes and load balancers",
                                "Can include detailed diagnostic information"
                            ],
                            keyConcepts: [
                                {
                                    name: "Liveness vs Readiness",
                                    explanation: "Liveness checks answer 'Is the application alive?' - if it fails, the container should be restarted. Readiness checks answer 'Is the application ready to serve traffic?' - if it fails, stop sending requests but don't restart. For example, your app might be alive but not ready if it's still warming up caches. Think of liveness as checking if someone is breathing, and readiness as checking if they're awake and ready to work."
                                },
                                {
                                    name: "Health Check Status",
                                    explanation: "Health checks return three possible statuses: Healthy (everything is fine), Degraded (working but with issues, like slow database), and Unhealthy (critical failure). Degraded is useful for alerting without taking the service offline. It's like a traffic light: green (healthy), yellow (degraded - proceed with caution), red (unhealthy - stop)."
                                },
                                {
                                    name: "Kubernetes Probes",
                                    explanation: "Kubernetes uses health check endpoints to manage containers. The liveness probe checks if a container is alive - if it fails repeatedly, Kubernetes restarts it. The readiness probe checks if a container can handle requests - if it fails, Kubernetes removes it from the load balancer temporarily. This enables self-healing infrastructure where unhealthy services are automatically recovered."
                                }
                            ]
                        },
                        {
                            id: 9,
                            question: "Explain async/await in C# and best practices for asynchronous programming in .NET Core.",
                            suggestedAnswer: "Async/await enables non-blocking asynchronous programming in C#. When you await an async operation like a database call or HTTP request, the thread is freed to handle other work instead of blocking. The async keyword marks a method as asynchronous, and await pauses execution until the awaited task completes, then resumes. Best practices include: always await async methods (don't use .Result or .Wait() as they cause deadlocks), use ConfigureAwait(false) in library code to avoid capturing context, prefer Task over async void except for event handlers, and propagate async all the way up (async all the way). Avoid mixing sync and async code. Use ValueTask for hot paths where the operation often completes synchronously. At BIPO with our microservices architecture, we use async/await extensively for database operations, external API calls, and message queue processing, which significantly improves throughput by allowing each service instance to handle more concurrent requests.",
                            bulletPoints: [
                                "Async/await enables non-blocking asynchronous operations",
                                "Frees threads to handle other work while waiting",
                                "Always await async methods, never use .Result or .Wait()",
                                "Use ConfigureAwait(false) in library code",
                                "Avoid async void except for event handlers",
                                "Propagate async all the way up the call stack",
                                "Use ValueTask for frequently synchronous operations"
                            ],
                            keyConcepts: [
                                {
                                    name: "Thread Pool Efficiency",
                                    explanation: "When you await an I/O operation, the thread doesn't sit idle waiting - it returns to the thread pool to handle other requests. When the I/O completes, a thread (possibly a different one) picks up where you left off. It's like a waiter taking multiple orders instead of standing at one table waiting for the kitchen - they can serve more customers with the same number of waiters."
                                },
                                {
                                    name: "Deadlock with .Result",
                                    explanation: "Calling .Result or .Wait() on a Task in certain contexts (like ASP.NET) can cause deadlocks. This happens because .Result blocks the current thread waiting for the task, but the task needs that same thread to complete. It's like waiting for yourself to finish - you're stuck forever. Always use await instead."
                                },
                                {
                                    name: "ConfigureAwait(false)",
                                    explanation: "By default, await captures the current synchronization context and resumes on it. ConfigureAwait(false) tells await not to capture the context, which improves performance in library code. In ASP.NET Core, this is less critical than in older frameworks, but it's still good practice for libraries. Think of it like not caring which checkout lane you return to at a store - any lane will do."
                                }
                            ]
                        },
                        {
                            id: 10,
                            question: "What are records in C# and how do they differ from classes?",
                            suggestedAnswer: "Records are reference types introduced in C# 9 designed for immutable data models. The key differences from classes are: records provide value-based equality by default (comparing property values, not references), built-in ToString() with all properties, with-expressions for non-destructive mutation, and positional syntax for concise declarations. Records are perfect for DTOs, API models, and domain value objects where you want immutability and value semantics. Classes use reference equality by default and are better for entities with identity and mutable state. Records can be declared as record class (reference type) or record struct (value type). I use records extensively for API request/response models, configuration objects, and domain events. At BIPO, we use records for all our API contracts and domain events in our event-driven architecture, which makes the code more concise and prevents accidental mutations.",
                            bulletPoints: [
                                "Records are reference types with value-based equality",
                                "Immutable by default with init-only properties",
                                "Built-in ToString() showing all properties",
                                "With-expressions for non-destructive mutation",
                                "Positional syntax: record Person(string Name, int Age)",
                                "Perfect for DTOs, API models, value objects",
                                "Classes better for entities with identity and mutable state"
                            ],
                            keyConcepts: [
                                {
                                    name: "Value-Based Equality",
                                    explanation: "Records compare equality based on property values, not object identity. Two record instances with the same property values are considered equal, even if they're different objects in memory. With classes, two instances are only equal if they're the exact same object (reference equality). It's like comparing two $20 bills - they're equal because of their value, not because they're the same physical bill."
                                },
                                {
                                    name: "With-Expressions",
                                    explanation: "With-expressions create a copy of a record with some properties changed, leaving the original unchanged. For example: var newPerson = person with { Age = 30 }. This is perfect for immutable data structures where you need to 'modify' values without actually mutating them. It's like making a photocopy of a document and changing one field on the copy."
                                },
                                {
                                    name: "Positional Records",
                                    explanation: "Positional records use a concise syntax: record Person(string Name, int Age). This automatically creates properties, a constructor, and deconstruction. It's shorthand that reduces boilerplate code dramatically. Instead of writing 10 lines of code for a simple data class, you write one line."
                                }
                            ]
                        },
                        {
                            id: 11,
                            question: "How do you implement global exception handling in .NET Core Web API?",
                            suggestedAnswer: "There are several approaches to global exception handling in .NET Core. The most common is using exception handling middleware with app.UseExceptionHandler() or custom middleware. You can also use an exception filter by implementing IExceptionFilter or IAsyncExceptionFilter. For middleware approach, create a custom middleware that wraps the next() call in try-catch, logs the exception, and returns a standardized error response. For filters, create a class implementing IExceptionFilter and register it globally. I prefer middleware for truly global handling and filters for controller-specific logic. The response should include appropriate status codes, error messages, and correlation IDs for tracing. Never expose stack traces in production. At Liven Group during our .NET 6 migration, we implemented global exception middleware that logged to CloudWatch, returned standardized error responses with correlation IDs, and handled different exception types appropriately - validation errors as 400, not found as 404, and unexpected errors as 500.",
                            bulletPoints: [
                                "Use app.UseExceptionHandler() for built-in exception handling",
                                "Create custom middleware with try-catch around next()",
                                "Implement IExceptionFilter for filter-based approach",
                                "Log exceptions with correlation IDs for tracing",
                                "Return standardized error responses with appropriate status codes",
                                "Never expose stack traces or sensitive data in production",
                                "Handle different exception types differently (validation, not found, server error)"
                            ],
                            keyConcepts: [
                                {
                                    name: "Exception Middleware",
                                    explanation: "Exception middleware sits early in the pipeline and wraps all subsequent middleware in a try-catch block. When any exception bubbles up, it catches it, logs it, and returns a user-friendly error response. It's like a safety net at a circus - no matter where someone falls from, the net catches them. This ensures no unhandled exceptions crash your application or leak sensitive information."
                                },
                                {
                                    name: "Correlation ID",
                                    explanation: "A correlation ID is a unique identifier for each request that's included in logs and error responses. When an error occurs, the user gets this ID, and support can use it to find the exact logs for that request. It's like a tracking number for a package - it lets you trace the entire journey of that specific request through your system, even across multiple services."
                                },
                                {
                                    name: "Exception Filters",
                                    explanation: "Exception filters are attributes or global filters that handle exceptions specifically for MVC/API controllers. They run after middleware but before the response is sent. They're useful for controller-specific exception handling, like converting domain exceptions to appropriate HTTP responses. Think of them as specialized handlers that understand the context of web requests better than generic middleware."
                                }
                            ]
                        },
                        {
                            id: 12,
                            question: "Explain the purpose and implementation of filters in ASP.NET Core (Action, Authorization, Exception, Resource, Result).",
                            suggestedAnswer: "Filters in ASP.NET Core are attributes that run code before or after specific stages in the request pipeline. Authorization filters run first and check if the user can access the resource. Resource filters run before model binding and after authorization - useful for caching. Action filters run before and after action method execution - good for logging or modifying arguments. Exception filters handle exceptions from actions. Result filters run before and after the action result executes - useful for modifying responses. You implement filters by inheriting from appropriate base classes or interfaces and registering them globally, per controller, or per action. Filters provide cross-cutting concerns without cluttering action methods. At BIPO, we use action filters for audit logging, authorization filters for multi-tenant access control, and result filters for response formatting and HATEOAS link injection in our REST APIs.",
                            bulletPoints: [
                                "Authorization filters: check user permissions (run first)",
                                "Resource filters: run before model binding, useful for caching",
                                "Action filters: run before/after action execution, for logging",
                                "Exception filters: handle exceptions from actions",
                                "Result filters: run before/after result execution, modify responses",
                                "Apply globally, per controller, or per action",
                                "Provide cross-cutting concerns without cluttering code"
                            ],
                            keyConcepts: [
                                {
                                    name: "Filter Pipeline Order",
                                    explanation: "Filters execute in a specific order: Authorization â†’ Resource â†’ Model Binding â†’ Action â†’ Exception (if error) â†’ Result. Understanding this order is crucial for proper implementation. For example, authorization must run before action to prevent unauthorized access. It's like security checkpoints at an airport - you go through them in a specific order, and each one serves a different purpose."
                                },
                                {
                                    name: "Cross-Cutting Concerns",
                                    explanation: "Cross-cutting concerns are functionalities that affect multiple parts of your application, like logging, security, or caching. Filters let you implement these concerns once and apply them across many actions without duplicating code. Instead of adding logging code to every action method, you write one logging filter and apply it everywhere."
                                },
                                {
                                    name: "Filter Scope",
                                    explanation: "Filters can be applied at three scopes: globally (affects all actions), controller-level (affects all actions in that controller), or action-level (affects only that specific action). You can also control order with the Order property. This flexibility lets you apply broad policies while still allowing specific overrides where needed."
                                }
                            ]
                        },
                        {
                            id: 13,
                            question: "What is the difference between ValueTask and Task in .NET?",
                            suggestedAnswer: "Task is a reference type that always allocates on the heap, while ValueTask is a value type that can avoid heap allocation when the operation completes synchronously. ValueTask is useful for hot paths where operations often complete synchronously, like reading from a cache that's usually in memory. However, ValueTask has restrictions: it should only be awaited once, and you shouldn't call .Result or .Wait() on it. For most scenarios, use Task. Use ValueTask only when profiling shows allocation pressure from frequently synchronous operations. ValueTask can wrap either a result or a Task, making it efficient for both sync and async paths. At BIPO, we use ValueTask in our caching layer where cache hits (synchronous) are common, and only cache misses require actual async database calls. This reduced our GC pressure significantly in high-throughput scenarios.",
                            bulletPoints: [
                                "Task: reference type, always heap allocated",
                                "ValueTask: value type, avoids allocation for synchronous completion",
                                "Use Task by default for most scenarios",
                                "Use ValueTask for hot paths with frequent synchronous completion",
                                "ValueTask restrictions: await only once, no .Result/.Wait()",
                                "ValueTask reduces GC pressure in high-throughput scenarios",
                                "Profile before optimizing - premature optimization is costly"
                            ],
                            keyConcepts: [
                                {
                                    name: "Heap Allocation",
                                    explanation: "Every time you create a Task, it allocates memory on the heap, which later needs garbage collection. In high-throughput scenarios with millions of operations, these allocations add up and cause GC pressure. ValueTask, being a value type, can live on the stack when the operation completes synchronously, avoiding this allocation. It's like using a reusable water bottle instead of disposable ones - less waste."
                                },
                                {
                                    name: "Synchronous Completion",
                                    explanation: "An operation completes synchronously when the result is immediately available without waiting. For example, reading from an in-memory cache is synchronous, while reading from a database is asynchronous. If your async method often completes synchronously (like 90% cache hits), ValueTask can optimize away the Task allocation for those cases while still supporting the async path when needed."
                                },
                                {
                                    name: "ValueTask Restrictions",
                                    explanation: "ValueTask is designed for a single consumption - you await it once and you're done. You can't await it multiple times or store it for later like you can with Task. This is because ValueTask might be backed by a pooled object that gets reused. Breaking these rules leads to subtle bugs. Think of it like a ticket that gets torn when used - you can't reuse it."
                                }
                            ]
                        },
                        {
                            id: 14,
                            question: "How do you implement rate limiting in .NET Core 8?",
                            suggestedAnswer: ".NET 8 includes built-in rate limiting middleware. You configure it with builder.Services.AddRateLimiter() and specify policies like Fixed Window, Sliding Window, Token Bucket, or Concurrency. Fixed Window allows X requests per time window. Sliding Window is similar but smoother. Token Bucket refills tokens at a rate, allowing bursts. Concurrency limits simultaneous requests. You apply policies globally or per endpoint with [EnableRateLimiting] attribute. You can also create custom policies. The middleware returns 429 Too Many Requests when limits are exceeded. For distributed systems, consider external solutions like Redis-based rate limiting. At BIPO, we use fixed window rate limiting on our public APIs to prevent abuse, with different limits for authenticated vs anonymous users. For internal microservice communication, we use concurrency limiters to prevent cascading failures when downstream services slow down.",
                            bulletPoints: [
                                "Built-in rate limiting in .NET 8 with AddRateLimiter()",
                                "Fixed Window: X requests per time period",
                                "Sliding Window: smoother than fixed window",
                                "Token Bucket: allows bursts with token refill",
                                "Concurrency: limits simultaneous requests",
                                "Apply globally or per endpoint with [EnableRateLimiting]",
                                "Returns 429 Too Many Requests when exceeded"
                            ],
                            keyConcepts: [
                                {
                                    name: "Fixed vs Sliding Window",
                                    explanation: "Fixed window counts requests in fixed time periods (e.g., 100 requests per minute starting at :00). This can allow 200 requests in a short burst (100 at :59 and 100 at 1:00). Sliding window tracks requests over a rolling time period, preventing this burst issue. It's like the difference between a monthly subscription that resets on the 1st versus one that resets exactly 30 days from when you signed up."
                                },
                                {
                                    name: "Token Bucket Algorithm",
                                    explanation: "Token bucket starts with a bucket of tokens. Each request consumes a token. Tokens refill at a constant rate. If the bucket is empty, requests are rejected. This allows bursts (using accumulated tokens) while maintaining an average rate. It's like a coffee shop punch card that refills one punch per day - you can save up punches for a busy day."
                                },
                                {
                                    name: "Distributed Rate Limiting",
                                    explanation: "When you have multiple servers, each server's in-memory rate limiter works independently, so the total limit is multiplied by the number of servers. For true distributed rate limiting, you need a shared state store like Redis where all servers check and update the same counters. This ensures the limit applies across your entire cluster, not per server."
                                }
                            ]
                        },
                        {
                            id: 15,
                            question: "Explain LINQ and provide examples of complex query operations you've implemented.",
                            suggestedAnswer: "LINQ (Language Integrated Query) provides a consistent query syntax for different data sources like collections, databases, and XML. It uses method syntax with lambda expressions or query syntax similar to SQL. Common operations include Where (filter), Select (project), GroupBy, Join, OrderBy, and aggregate functions. LINQ to Entities translates to SQL for databases. Complex examples I've implemented include: multi-level grouping with aggregations for reporting, left joins with multiple conditions, nested queries with SelectMany for flattening hierarchies, and combining multiple data sources. At Liven Group, I used LINQ extensively for complex restaurant analytics - grouping orders by location and time period with revenue calculations, joining menu items with sales data across multiple databases (SQL Server and PostgreSQL), and using projection to optimize queries by selecting only needed fields. At BIPO, I implemented complex payroll calculations using LINQ to aggregate employee data across multiple countries with different tax rules.",
                            bulletPoints: [
                                "Language Integrated Query for consistent query syntax",
                                "Works with collections, databases (EF), XML, and more",
                                "Method syntax: collection.Where(x => x.Age > 18).Select(x => x.Name)",
                                "Query syntax: from x in collection where x.Age > 18 select x.Name",
                                "Common operations: Where, Select, GroupBy, Join, OrderBy, Sum, Count",
                                "LINQ to Entities translates to SQL for database queries",
                                "Deferred execution: query runs when enumerated, not when defined"
                            ],
                            keyConcepts: [
                                {
                                    name: "Deferred Execution",
                                    explanation: "LINQ queries don't execute when you write them - they execute when you enumerate the results (foreach, ToList(), Count(), etc.). This means you can build up complex queries step by step, and the actual data retrieval happens only once at the end. It's like writing a shopping list throughout the week but only going to the store on Saturday - you make one trip with the complete list."
                                },
                                {
                                    name: "Expression Trees",
                                    explanation: "When you use LINQ with Entity Framework, your lambda expressions are converted to expression trees - data structures representing the code. EF then translates these to SQL. This is why you can't use arbitrary C# methods in LINQ to Entities - they need to be translatable to SQL. It's like having a translator who can only translate certain phrases, not everything you might say."
                                },
                                {
                                    name: "IEnumerable vs IQueryable",
                                    explanation: "IEnumerable executes queries in memory using LINQ to Objects. IQueryable builds expression trees and executes on the data source (like SQL Server). If you call ToList() too early, you pull all data into memory and filter there. Keep queries as IQueryable until the last moment to let the database do the heavy lifting. It's like filtering water at the source versus filling a pool and filtering it after."
                                }
                            ]
                        }
                    ]
                },
                {
                    id: 2,
                    name: "API Design & Swagger",
                    questions: [
                        {
                            id: 16,
                            question: "What are RESTful API design principles and how do you apply them?",
                            suggestedAnswer: "RESTful APIs follow six key principles: client-server architecture, statelessness, cacheability, layered system, uniform interface, and code on demand (optional). The uniform interface includes resource identification via URIs, manipulation through representations, self-descriptive messages, and HATEOAS. Use HTTP verbs correctly: GET for retrieval, POST for creation, PUT for full updates, PATCH for partial updates, DELETE for removal. Resources should be nouns, not verbs. Use proper status codes: 2xx for success, 4xx for client errors, 5xx for server errors. Keep APIs stateless - each request contains all needed information. Design for idempotency where possible. At BIPO, our invoice management API follows REST principles with resource-based URIs like /api/invoices/{id}, proper HTTP verb usage, and consistent response formats. We use HATEOAS for navigation links and implement caching headers for frequently accessed resources.",
                            bulletPoints: [
                                "Use HTTP verbs correctly: GET, POST, PUT, PATCH, DELETE",
                                "Resources as nouns in URIs: /api/users, not /api/getUsers",
                                "Stateless: each request self-contained",
                                "Proper status codes: 2xx success, 4xx client error, 5xx server error",
                                "Idempotent operations where possible (PUT, DELETE)",
                                "Use HTTP headers for metadata (Content-Type, Authorization)",
                                "HATEOAS for discoverability (optional but recommended)"
                            ],
                            keyConcepts: [
                                {
                                    name: "Statelessness",
                                    explanation: "Stateless means the server doesn't store any client context between requests. Each request must contain all information needed to process it (like authentication tokens). This makes scaling easier because any server can handle any request - you don't need sticky sessions. It's like going to a different bank teller each time and showing your ID every time, rather than one teller remembering you."
                                },
                                {
                                    name: "Idempotency",
                                    explanation: "An idempotent operation produces the same result no matter how many times you call it. PUT and DELETE should be idempotent - updating a user with the same data twice has the same effect as once, deleting something twice doesn't cause an error. This is important for reliability when requests might be retried. It's like pressing an elevator button multiple times - the elevator still only comes once."
                                },
                                {
                                    name: "Resource-Based Design",
                                    explanation: "REST APIs are organized around resources (things) rather than actions. You use HTTP verbs to specify the action on the resource. For example, GET /users/123 gets a user, DELETE /users/123 deletes them. This is cleaner than having /getUser?id=123 and /deleteUser?id=123. Resources should be nouns representing business entities."
                                }
                            ]
                        },
                        {
                            id: 17,
                            question: "How do you version APIs in .NET Core and what are the different versioning strategies?",
                            suggestedAnswer: "There are four main API versioning strategies. URL versioning puts version in the path: /api/v1/users. Query string versioning uses a parameter: /api/users?api-version=1.0. Header versioning uses custom headers: X-API-Version: 1.0. Media type versioning uses Accept header: application/vnd.company.v1+json. In .NET Core, use Microsoft.AspNetCore.Mvc.Versioning package. Configure with AddApiVersioning() and specify how to read version (URL, query, header). You can support multiple versions simultaneously and deprecate old versions gracefully. URL versioning is most visible and cache-friendly. Header versioning keeps URLs clean. I prefer URL versioning for public APIs due to clarity and ease of testing. At BIPO, we use URL versioning for our public APIs with a deprecation policy that gives clients 6 months notice before removing old versions.",
                            bulletPoints: [
                                "URL versioning: /api/v1/users (most visible, cache-friendly)",
                                "Query string: /api/users?api-version=1.0",
                                "Header versioning: X-API-Version: 1.0 (clean URLs)",
                                "Media type: Accept: application/vnd.company.v1+json",
                                "Use Microsoft.AspNetCore.Mvc.Versioning package",
                                "Support multiple versions simultaneously",
                                "Implement deprecation policy for old versions"
                            ],
                            keyConcepts: [
                                {
                                    name: "Breaking vs Non-Breaking Changes",
                                    explanation: "Breaking changes require a new API version because they break existing clients (removing fields, changing data types, changing behavior). Non-breaking changes don't require new versions (adding optional fields, new endpoints). Understanding this distinction helps you decide when to bump versions. It's like renovating a house - adding a room is non-breaking, but changing the front door location breaks everyone's muscle memory."
                                },
                                {
                                    name: "API Deprecation",
                                    explanation: "Deprecation is the process of phasing out old API versions. You announce a version is deprecated, give clients time to migrate, then eventually remove it. Good practice includes setting deprecation headers, documenting migration guides, and providing reasonable timelines. It's like a store announcing it's closing - you give customers advance notice and time to find alternatives."
                                },
                                {
                                    name: "Version Negotiation",
                                    explanation: "Version negotiation is how the API determines which version to use when a client makes a request. You can have default versions, require explicit versions, or support version ranges. The versioning middleware handles this automatically based on your configuration. Think of it like a restaurant menu with seasonal items - the server knows which version of the menu to bring based on what you ask for."
                                }
                            ]
                        },
                        {
                            id: 18,
                            question: "Explain how to configure and customize Swagger/OpenAPI documentation in .NET Core.",
                            suggestedAnswer: "Swagger/OpenAPI documentation is configured using Swashbuckle.AspNetCore package. Add services with AddSwaggerGen() in Program.cs, configure metadata like title, version, description, and contact info. Use XML comments by enabling XML documentation file in project settings and calling IncludeXmlComments(). Customize with operation filters, document filters, and schema filters for advanced scenarios. Add examples using [SwaggerOperation] and [SwaggerResponse] attributes. Configure authentication schemes with AddSecurityDefinition() and AddSecurityRequirement(). Group endpoints by tags. Customize UI with SwaggerUI options. At BIPO, we generate comprehensive API documentation with XML comments on all public endpoints, include request/response examples, document all possible status codes, and configure JWT bearer authentication in Swagger UI so developers can test authenticated endpoints directly from the documentation.",
                            bulletPoints: [
                                "Install Swashbuckle.AspNetCore package",
                                "Configure with AddSwaggerGen() and UseSwagger()/UseSwaggerUI()",
                                "Enable XML comments for detailed documentation",
                                "Add metadata: title, version, description, contact",
                                "Configure authentication with AddSecurityDefinition()",
                                "Use attributes: [SwaggerOperation], [SwaggerResponse]",
                                "Customize with filters: IOperationFilter, IDocumentFilter"
                            ],
                            keyConcepts: [
                                {
                                    name: "OpenAPI Specification",
                                    explanation: "OpenAPI (formerly Swagger) is a standard format for describing REST APIs. It's a JSON/YAML document that describes all your endpoints, parameters, responses, and authentication. Tools can read this spec to generate documentation, client SDKs, and test cases. It's like a blueprint for your API that both humans and machines can understand."
                                },
                                {
                                    name: "XML Documentation Comments",
                                    explanation: "XML comments (/// <summary>) in your C# code can be included in Swagger documentation. This lets you write API docs right next to the code, keeping them in sync. When you enable XML documentation file generation, Swashbuckle reads these comments and adds them to the OpenAPI spec. It's like adding sticky notes to your code that also appear in the user manual."
                                },
                                {
                                    name: "Swagger Filters",
                                    explanation: "Filters let you customize how Swagger generates documentation. Operation filters modify individual endpoints, document filters modify the entire spec, and schema filters modify model schemas. You might use filters to add custom headers, hide internal endpoints, or enrich examples. They're like post-processing steps that refine the generated documentation."
                                }
                            ]
                        },
                        {
                            id: 19,
                            question: "How do you implement authentication and authorization in Swagger UI?",
                            suggestedAnswer: "To add authentication to Swagger UI, configure security definitions in AddSwaggerGen(). For JWT Bearer, use AddSecurityDefinition with type Bearer and scheme bearer. Then add AddSecurityRequirement to apply it globally or use [Authorize] attributes on controllers. For OAuth2, configure flows (authorization code, implicit, etc.) with token and authorization URLs. In Swagger UI, users click the Authorize button, enter credentials or tokens, and subsequent requests include authentication headers. You can also configure API keys or Basic authentication. At BIPO, we implement JWT Bearer authentication in Swagger with AddSecurityDefinition specifying the bearer scheme. Developers can click Authorize, paste their JWT token, and test all authenticated endpoints. This significantly improves developer experience as they can test the entire API including secured endpoints directly from the documentation.",
                            bulletPoints: [
                                "Configure security in AddSwaggerGen() with AddSecurityDefinition()",
                                "JWT Bearer: type Bearer, scheme bearer",
                                "OAuth2: configure flows with token/authorization URLs",
                                "API Key: specify in header, query, or cookie",
                                "Add AddSecurityRequirement() for global application",
                                "Users click Authorize button in Swagger UI",
                                "Supports multiple authentication schemes simultaneously"
                            ],
                            keyConcepts: [
                                {
                                    name: "Security Definitions",
                                    explanation: "Security definitions tell Swagger what authentication methods your API supports. You define the type (Bearer, OAuth2, API Key, Basic), where to send credentials (header, query, cookie), and any additional parameters. This information is used to render the Authorize button and dialog in Swagger UI. It's like telling the documentation what keys are needed to unlock different doors."
                                },
                                {
                                    name: "Security Requirements",
                                    explanation: "Security requirements specify which endpoints need which authentication. You can apply them globally (all endpoints), per controller, or per action. This determines which endpoints show the lock icon in Swagger UI. When you authorize in Swagger, it automatically adds the auth headers to requests for endpoints with security requirements."
                                },
                                {
                                    name: "Bearer Token",
                                    explanation: "Bearer token authentication means the client sends a token (usually JWT) in the Authorization header as 'Bearer {token}'. The server validates this token to authenticate the request. In Swagger UI, users paste their token once, and it's automatically included in all subsequent requests. It's like showing a VIP pass at a club - once you show it, you're recognized for the rest of the night."
                                }
                            ]
                        },
                        {
                            id: 20,
                            question: "What are the best practices for API error handling and status code usage?",
                            suggestedAnswer: "Use appropriate HTTP status codes: 200 OK for success, 201 Created for resource creation, 204 No Content for successful deletion, 400 Bad Request for validation errors, 401 Unauthorized for missing/invalid authentication, 403 Forbidden for insufficient permissions, 404 Not Found for missing resources, 409 Conflict for business rule violations, 422 Unprocessable Entity for semantic errors, 429 Too Many Requests for rate limiting, 500 Internal Server Error for unexpected errors, 503 Service Unavailable for temporary outages. Return consistent error response format with error code, message, and details. Include correlation IDs for tracing. Use ProblemDetails (RFC 7807) format. Never expose stack traces or sensitive information in production. Log all errors with context. At BIPO, we use a standardized error response format across all microservices with error codes, user-friendly messages, field-level validation errors, and correlation IDs that link to our distributed tracing system.",
                            bulletPoints: [
                                "2xx: Success (200 OK, 201 Created, 204 No Content)",
                                "4xx: Client errors (400 Bad Request, 401 Unauthorized, 403 Forbidden, 404 Not Found)",
                                "5xx: Server errors (500 Internal Server Error, 503 Service Unavailable)",
                                "Use ProblemDetails (RFC 7807) for consistent error format",
                                "Include correlation IDs for tracing",
                                "Provide field-level validation errors",
                                "Never expose stack traces or sensitive data in production"
                            ],
                            keyConcepts: [
                                {
                                    name: "ProblemDetails Format",
                                    explanation: "ProblemDetails is a standard format (RFC 7807) for error responses in HTTP APIs. It includes type (error category), title (short description), status (HTTP code), detail (explanation), and instance (correlation ID). Using this standard makes your API consistent with industry practices and easier for clients to handle. It's like having a standard form for reporting issues - everyone knows where to find the information they need."
                                },
                                {
                                    name: "4xx vs 5xx Errors",
                                    explanation: "4xx errors mean the client made a mistake (bad request, unauthorized, not found) - the client should fix something and retry. 5xx errors mean the server had a problem - the client's request was fine, but the server couldn't process it. This distinction helps clients know whether to retry (5xx) or fix their request (4xx). It's like the difference between 'you wrote the wrong address' (4xx) versus 'the post office is closed' (5xx)."
                                },
                                {
                                    name: "Error Granularity",
                                    explanation: "Good error responses provide enough detail for clients to fix the problem without exposing security risks. For validation errors, specify which fields failed and why. For business rule violations, explain what rule was broken. But never expose implementation details, database errors, or stack traces. It's like telling someone their password is wrong without revealing what the correct password is."
                                }
                            ]
                        },
                        {
                            id: 21,
                            question: "How do you implement pagination, filtering, and sorting in Web APIs?",
                            suggestedAnswer: "Pagination prevents loading large datasets by returning data in pages. Use query parameters like pageNumber and pageSize (e.g., /api/users?pageNumber=1&pageSize=20). Return metadata in headers or response body: totalCount, totalPages, hasNext, hasPrevious. For filtering, use query parameters matching property names (/api/users?status=active&role=admin). For sorting, use a sort parameter with field and direction (/api/users?sortBy=lastName&sortOrder=desc). Implement using LINQ Skip() and Take() for pagination, Where() for filtering, and OrderBy() for sorting. Consider cursor-based pagination for large datasets. Return links to next/previous pages (HATEOAS). At Liven Group, I implemented pagination for restaurant order lists with cursor-based pagination for real-time order streams, and at BIPO for employee lists across multiple countries with complex filtering by country, department, and employment status, plus sorting by multiple fields.",
                            bulletPoints: [
                                "Pagination: pageNumber and pageSize query parameters",
                                "Return metadata: totalCount, totalPages, hasNext, hasPrevious",
                                "Filtering: property-based query parameters",
                                "Sorting: sortBy and sortOrder parameters",
                                "Implement with LINQ: Skip(), Take(), Where(), OrderBy()",
                                "Cursor-based pagination for large/real-time datasets",
                                "Include navigation links (next, previous, first, last)"
                            ],
                            keyConcepts: [
                                {
                                    name: "Offset vs Cursor Pagination",
                                    explanation: "Offset pagination uses page numbers (skip X, take Y). It's simple but can miss or duplicate items if data changes between requests. Cursor pagination uses a unique identifier (like last seen ID) to fetch the next batch. It's more reliable for real-time data but harder to implement. Think of offset like saying 'give me page 5' versus cursor like saying 'give me items after ID 12345'."
                                },
                                {
                                    name: "Pagination Metadata",
                                    explanation: "Pagination metadata tells clients about the dataset: how many total items, how many pages, whether there are more pages. You can return this in response headers (X-Total-Count, Link header) or in the response body. This lets clients build proper UI pagination controls. It's like a book telling you 'page 5 of 200' so you know how much more there is to read."
                                },
                                {
                                    name: "Query Parameter Design",
                                    explanation: "Good query parameter design makes APIs intuitive. Use consistent naming (camelCase or snake_case), support multiple filters, allow combining filters with AND logic, and document all options. For complex scenarios, consider POST with a filter object in the body instead of dozens of query parameters. Keep it simple for common cases, powerful for complex ones."
                                }
                            ]
                        },
                        {
                            id: 22,
                            question: "Explain content negotiation in ASP.NET Core Web API.",
                            suggestedAnswer: "Content negotiation is how the client and server agree on the response format. The client specifies preferred formats using the Accept header (e.g., Accept: application/json or Accept: application/xml). ASP.NET Core examines this header and returns data in the requested format if supported. By default, ASP.NET Core supports JSON. To add XML support, call AddXmlSerializerFormatters() or AddXmlDataContractSerializerFormatters(). You can create custom formatters for other formats like CSV or Protocol Buffers. The framework automatically serializes your response objects to the negotiated format. If the requested format isn't supported, it returns 406 Not Acceptable or falls back to a default format. At BIPO, we support both JSON and XML for our invoice API to accommodate different client systems, with JSON as the default and XML available for legacy integrations.",
                            bulletPoints: [
                                "Client specifies format with Accept header",
                                "Server returns data in requested format if supported",
                                "Default support for JSON in ASP.NET Core",
                                "Add XML with AddXmlSerializerFormatters()",
                                "Create custom formatters for CSV, Protocol Buffers, etc.",
                                "Returns 406 Not Acceptable if format unsupported",
                                "Can configure default format and fallback behavior"
                            ],
                            keyConcepts: [
                                {
                                    name: "Accept Header",
                                    explanation: "The Accept header tells the server what content types the client can handle, with optional quality values for preferences (e.g., Accept: application/json, application/xml;q=0.9). The server picks the best match. If you don't specify Accept, you typically get the default format (JSON). It's like ordering at a restaurant and saying 'I prefer steak, but chicken is okay too'."
                                },
                                {
                                    name: "Output Formatters",
                                    explanation: "Output formatters are components that serialize your C# objects into specific formats (JSON, XML, etc.). ASP.NET Core includes JSON formatter by default. You can add more formatters or create custom ones by implementing IOutputFormatter. The framework automatically picks the right formatter based on content negotiation. Think of formatters as translators that convert your data into different languages."
                                },
                                {
                                    name: "Media Types",
                                    explanation: "Media types (MIME types) identify content formats: application/json for JSON, application/xml for XML, text/csv for CSV, etc. They're standardized identifiers so clients and servers speak the same language about formats. You can also define custom media types for your API-specific formats, like application/vnd.company.invoice+json."
                                }
                            ]
                        },
                        {
                            id: 23,
                            question: "How do you implement CORS in .NET Core and what security considerations should you keep in mind?",
                            suggestedAnswer: "CORS (Cross-Origin Resource Sharing) allows web applications from different domains to access your API. Configure it in Program.cs with AddCors() to define policies and UseCors() to apply them. You can allow specific origins, all origins (not recommended for production), specific HTTP methods, and specific headers. For credentials (cookies, auth headers), you must specify exact origins, not wildcards. Apply CORS globally or per controller/action. Security considerations: never use AllowAnyOrigin with AllowCredentials, whitelist specific origins in production, be careful with AllowAnyHeader, validate origin dynamically if needed, and consider CORS as one layer of security, not the only one. At BIPO, we configure CORS to allow our React frontend domains (development, staging, production) with credentials enabled for JWT cookies, and we dynamically validate origins against a configuration list for multi-tenant scenarios.",
                            bulletPoints: [
                                "Configure with AddCors() and apply with UseCors()",
                                "Specify allowed origins, methods, and headers",
                                "Never use AllowAnyOrigin() with AllowCredentials()",
                                "Whitelist specific origins in production",
                                "Apply globally or per controller/action",
                                "CORS is browser security, not API security",
                                "Consider preflight request caching for performance"
                            ],
                            keyConcepts: [
                                {
                                    name: "Same-Origin Policy",
                                    explanation: "Browsers enforce same-origin policy: a web page can only make requests to the same domain it came from. This prevents malicious sites from stealing data. CORS is a way to selectively relax this restriction by having the server say 'I allow requests from these other domains'. It's like a bouncer at a club who normally only lets in members, but the owner can say 'also let in people from this other club'."
                                },
                                {
                                    name: "Preflight Requests",
                                    explanation: "For certain requests (like PUT, DELETE, or custom headers), browsers send a preflight OPTIONS request first to check if CORS allows it. The server responds with allowed methods and headers. Only if approved does the browser send the actual request. This adds overhead, so you can cache preflight responses. It's like asking permission before doing something, rather than doing it and apologizing later."
                                },
                                {
                                    name: "CORS vs API Security",
                                    explanation: "CORS is a browser security feature - it doesn't protect your API from non-browser clients like Postman or cURL. You still need proper authentication and authorization. CORS just prevents unauthorized websites from making requests from users' browsers. Think of CORS as controlling which websites can use your API through a browser, not controlling who can access your API in general."
                                }
                            ]
                        },
                        {
                            id: 24,
                            question: "What is HATEOAS and when would you implement it in your API?",
                            suggestedAnswer: "HATEOAS (Hypermedia As The Engine Of Application State) is a REST constraint where responses include links to related resources and available actions. Instead of clients hardcoding URLs, the API tells them what they can do next. For example, a GET /orders/123 response includes links to update, cancel, or view related customer. This makes APIs self-documenting and evolvable - you can change URLs without breaking clients. Implement HATEOAS when building public APIs, when you want loose coupling between client and server, or when you need API discoverability. It adds complexity, so skip it for simple internal APIs or when clients are tightly coupled anyway. At BIPO, we implement HATEOAS in our public invoice API, where each invoice response includes links to related actions (pay, download PDF, view customer) and navigation (next/previous invoices), making it easier for third-party integrators to discover and use our API without extensive documentation.",
                            bulletPoints: [
                                "Include hypermedia links in responses",
                                "Links show available actions and related resources",
                                "Makes APIs self-documenting and discoverable",
                                "Allows URL changes without breaking clients",
                                "Use for public APIs and loose coupling",
                                "Skip for simple internal APIs (adds complexity)",
                                "Common formats: HAL, JSON:API, Siren"
                            ],
                            keyConcepts: [
                                {
                                    name: "Hypermedia Links",
                                    explanation: "Hypermedia links in API responses tell clients what actions are available and how to perform them. Each link has a relation (rel) describing what it does and an href with the URL. For example, a 'self' link points to the current resource, a 'next' link to the next page. It's like a website with navigation links - you don't need to know all URLs upfront, you just follow the links."
                                },
                                {
                                    name: "API Discoverability",
                                    explanation: "Discoverability means clients can explore your API by following links, without reading extensive documentation. Start at a root endpoint, see what links are available, follow them to discover more. This is especially valuable for public APIs where you don't control the clients. It's like exploring a city by following street signs versus needing a detailed map memorized in advance."
                                },
                                {
                                    name: "Loose Coupling",
                                    explanation: "HATEOAS enables loose coupling because clients don't hardcode URLs - they follow links provided by the server. If you change a URL structure, clients still work because they're following the links you provide. This makes your API more maintainable and evolvable. It's like giving someone directions turn-by-turn versus giving them an address - if the route changes, turn-by-turn directions still get them there."
                                }
                            ]
                        },
                        {
                            id: 25,
                            question: "How do you handle file uploads and downloads in Web API?",
                            suggestedAnswer: "For file uploads, use IFormFile parameter with [FromForm] attribute. For multiple files, use IFormFileCollection or List<IFormFile>. Validate file size, type, and content before processing. Stream large files instead of loading entirely into memory. Save to disk, database, or cloud storage like Azure Blob Storage. For downloads, return File() result with file stream, content type, and filename. Use FileStreamResult for large files to stream them. Set appropriate headers: Content-Disposition for download behavior, Content-Type for file type. Implement resumable uploads for large files using chunking. Consider virus scanning for uploaded files. At Liven Group, we handled menu image uploads to S3 with validation and resizing. At BIPO, we process bulk employee data CSV uploads with streaming to handle files with hundreds of thousands of rows, and generate PDF payslips for download with proper content disposition headers.",
                            bulletPoints: [
                                "Upload: use IFormFile with [FromForm] attribute",
                                "Validate file size, type, and content",
                                "Stream large files, don't load entirely into memory",
                                "Save to Azure Blob Storage, S3, or local disk",
                                "Download: return File() with stream, content type, filename",
                                "Set Content-Disposition header for download behavior",
                                "Consider chunked uploads for large files"
                            ],
                            keyConcepts: [
                                {
                                    name: "File Streaming",
                                    explanation: "Streaming means processing a file in chunks rather than loading it entirely into memory. This is crucial for large files - a 1GB file would consume 1GB of RAM if loaded fully. With streaming, you read and process small chunks at a time, keeping memory usage constant. It's like drinking from a water fountain versus filling a bucket first - much more efficient for large amounts."
                                },
                                {
                                    name: "Content-Disposition Header",
                                    explanation: "Content-Disposition tells the browser how to handle the file: 'inline' displays it in the browser (like PDFs), 'attachment' triggers a download. You can also specify the filename. For example: Content-Disposition: attachment; filename=invoice.pdf. This controls whether users see the file or download it. It's like the difference between showing someone a document versus handing them a copy to take home."
                                },
                                {
                                    name: "File Validation",
                                    explanation: "Never trust file uploads. Validate file size to prevent DoS attacks, check file extensions and MIME types to prevent malicious uploads, and ideally scan content for viruses. Don't rely solely on client-side validation - always validate server-side. Store uploaded files outside the web root to prevent execution. It's like checking IDs at a door - you can't just trust everyone who walks in."
                                }
                            ]
                        }
                    ]
                },
                {
                    id: 3,
                    name: "Entity Framework & SQL",
                    questions: [
                        {
                            id: 26,
                            question: "What is Entity Framework Core and how does it differ from Entity Framework 6?",
                            suggestedAnswer: "Entity Framework Core is a lightweight, cross-platform ORM (Object-Relational Mapper) that's a complete rewrite of EF6. Key differences: EF Core is cross-platform (Windows, Linux, macOS) while EF6 is Windows-only. EF Core is lighter and faster with better performance. EF Core supports more database providers including NoSQL. EF Core has better LINQ translation and query performance. EF Core uses a simpler configuration API with fluent API and data annotations. However, EF6 has some features EF Core initially lacked like lazy loading by default (now available via proxies), automatic migrations, and some advanced mapping scenarios. EF Core is the future and actively developed. At Liven Group, we migrated from EF6 to EF Core during our .NET 6 upgrade, benefiting from improved query performance and cross-platform support for our Docker deployments. At BIPO, we use EF Core exclusively across all microservices with SQL Server, MongoDB provider, and DynamoDB.",
                            bulletPoints: [
                                "EF Core: cross-platform, lightweight, modern rewrite",
                                "EF6: Windows-only, mature, feature-complete",
                                "EF Core: better performance and LINQ translation",
                                "EF Core: supports more database providers",
                                "EF Core: simpler configuration with fluent API",
                                "EF Core: no lazy loading by default (opt-in with proxies)",
                                "EF Core is actively developed, EF6 is maintenance mode"
                            ],
                            keyConcepts: [
                                {
                                    name: "ORM (Object-Relational Mapper)",
                                    explanation: "An ORM maps database tables to C# classes and rows to objects, letting you work with databases using object-oriented code instead of writing SQL. You query and manipulate objects, and the ORM translates to SQL behind the scenes. It's like having a translator between your C# code and the database - you speak C#, the database speaks SQL, and the ORM translates."
                                },
                                {
                                    name: "Cross-Platform Support",
                                    explanation: "EF Core runs on Windows, Linux, and macOS, while EF6 only runs on Windows. This is crucial for Docker containers and cloud deployments where you might use Linux for cost savings. Cross-platform means you can develop on Mac, test on Linux, and deploy anywhere. It's like a car that runs on any type of road versus one that only works on highways."
                                },
                                {
                                    name: "Database Providers",
                                    explanation: "Database providers are plugins that let EF Core work with different databases. There are providers for SQL Server, PostgreSQL, MySQL, SQLite, Cosmos DB, and even in-memory databases for testing. You can switch providers with minimal code changes. It's like having universal adapters that let you plug your device into any outlet worldwide."
                                }
                            ]
                        },
                        {
                            id: 27,
                            question: "Explain the difference between Code First, Database First, and Model First approaches in EF Core.",
                            suggestedAnswer: "Code First means you write C# entity classes first, and EF Core generates the database schema from them using migrations. This is the most common approach in modern development, giving you full control over your domain model. Database First means you have an existing database and use scaffolding (dotnet ef dbcontext scaffold) to generate entity classes from it. This is useful for legacy databases or when the database is designed separately. Model First (using visual designers) is not supported in EF Core - it was an EF6 feature. In EF Core, you choose between Code First or Database First. Code First is preferred for new projects as it keeps your code as the source of truth and enables version control of schema changes through migrations. At BIPO, we use Code First exclusively for all new microservices, defining entities in code and using migrations to evolve the schema. At Liven Group during migration, we used Database First to scaffold existing databases, then switched to Code First for ongoing development.",
                            bulletPoints: [
                                "Code First: write C# classes, generate database from code",
                                "Database First: existing database, scaffold C# classes from it",
                                "Model First: not supported in EF Core (was EF6 feature)",
                                "Code First: best for new projects, code is source of truth",
                                "Database First: useful for legacy databases",
                                "Code First uses migrations for schema changes",
                                "Database First uses scaffolding command"
                            ],
                            keyConcepts: [
                                {
                                    name: "Migrations",
                                    explanation: "Migrations are version-controlled schema changes. When you modify entity classes in Code First, you create a migration that describes the changes (add column, create table, etc.). You can apply migrations to update the database or roll them back. It's like Git commits for your database schema - each migration is a checkpoint you can move forward or backward through."
                                },
                                {
                                    name: "Scaffolding",
                                    explanation: "Scaffolding is the process of generating C# entity classes and DbContext from an existing database. EF Core reads the database schema and creates corresponding classes. This is a one-time generation, though you can re-scaffold if the database changes. Think of it like reverse engineering - you're working backwards from the database to create code."
                                },
                                {
                                    name: "Source of Truth",
                                    explanation: "The source of truth is the authoritative definition of your data model. In Code First, it's your C# classes. In Database First, it's the database schema. Having code as source of truth is generally better because code can be version controlled, reviewed, and tested more easily than database schemas. It's like having the recipe (code) versus just the finished dish (database)."
                                }
                            ]
                        },
                        {
                            id: 28,
                            question: "How do you optimize Entity Framework queries for performance?",
                            suggestedAnswer: "Key EF Core optimization techniques: Use AsNoTracking() for read-only queries to avoid change tracking overhead. Use Select() to project only needed columns instead of loading entire entities. Implement eager loading with Include() to avoid N+1 problems. Use compiled queries for frequently executed queries. Avoid loading navigation properties you don't need. Use pagination with Skip() and Take() for large datasets. Use AsSplitQuery() for multiple Include() to avoid cartesian explosion. Profile queries with logging or tools like EF Core Plus. Add appropriate database indexes. Use raw SQL for complex queries that don't translate well. Batch operations instead of individual saves. At Liven Group, I optimized restaurant order queries by using AsNoTracking for read-only dashboards, adding indexes on frequently queried columns, and using Select projections to load only display fields. At BIPO, we use compiled queries for frequently-run payroll calculations and split queries for complex employee data with multiple includes.",
                            bulletPoints: [
                                "Use AsNoTracking() for read-only queries",
                                "Project with Select() to load only needed columns",
                                "Eager load with Include() to prevent N+1 queries",
                                "Use compiled queries for frequently executed queries",
                                "Implement pagination with Skip() and Take()",
                                "Use AsSplitQuery() to avoid cartesian explosion",
                                "Add database indexes on frequently queried columns",
                                "Use raw SQL for complex queries"
                            ],
                            keyConcepts: [
                                {
                                    name: "Change Tracking",
                                    explanation: "Change tracking is EF Core's mechanism for detecting changes to entities so it can generate UPDATE statements. It keeps a snapshot of original values and compares them when you call SaveChanges(). This has overhead - memory and CPU. For read-only queries where you won't modify data, use AsNoTracking() to skip this overhead. It's like the difference between borrowing a book you might write notes in versus just reading it at the library."
                                },
                                {
                                    name: "Cartesian Explosion",
                                    explanation: "Cartesian explosion happens when you Include() multiple collections in one query. EF Core joins them, creating duplicate parent data for each combination of children. A parent with 10 items in collection A and 10 in collection B results in 100 rows. AsSplitQuery() runs separate queries for each collection, avoiding this. It's like getting one big package versus multiple smaller packages - sometimes separate is more efficient."
                                },
                                {
                                    name: "Compiled Queries",
                                    explanation: "Compiled queries are pre-compiled LINQ expressions that EF Core doesn't need to translate every time. For queries executed frequently with different parameters, compiling them once improves performance. It's like having a template letter where you just fill in the name, versus writing a new letter from scratch each time."
                                }
                            ]
                        },
                        {
                            id: 29,
                            question: "What is the N+1 query problem and how do you solve it in EF Core?",
                            suggestedAnswer: "The N+1 problem occurs when you load a collection of entities (1 query), then access a navigation property for each entity (N queries), resulting in N+1 total queries. For example, loading 100 orders then accessing order.Customer for each causes 101 queries. This severely impacts performance. Solutions: Use eager loading with Include() to load related data in the initial query. Use Select() to project needed data in one query. Use explicit loading with Load() if you need related data conditionally. Enable lazy loading carefully (it can hide N+1 problems). Use AsSplitQuery() for multiple includes. Profile your queries to detect N+1 issues. At BIPO, I encountered N+1 when displaying employee lists with department names - initially 1 query for employees plus 1 per employee for department. Fixed by adding Include(e => e.Department), reducing to 1 query. Always check generated SQL with logging or profilers.",
                            bulletPoints: [
                                "N+1: one query for collection, N queries for related data",
                                "Causes severe performance degradation",
                                "Solution: eager loading with Include()",
                                "Solution: projection with Select()",
                                "Solution: explicit loading with Load() when conditional",
                                "Avoid lazy loading or use carefully",
                                "Profile queries to detect N+1 problems",
                                "Check generated SQL with logging"
                            ],
                            keyConcepts: [
                                {
                                    name: "Eager Loading",
                                    explanation: "Eager loading means loading related data upfront in the same query using Include(). Instead of separate queries for each relationship, everything loads together with JOINs. This solves N+1 by making it 1 query instead of N+1. It's like getting all your groceries in one trip versus making a separate trip for each item."
                                },
                                {
                                    name: "Lazy Loading",
                                    explanation: "Lazy loading automatically loads navigation properties when you access them. It's convenient but dangerous because it hides database calls and easily causes N+1 problems. In EF Core, lazy loading is opt-in using proxies. For most scenarios, explicit eager or explicit loading is better because you control when queries happen. It's like automatic bill pay - convenient but you might not notice unexpected charges."
                                },
                                {
                                    name: "Query Profiling",
                                    explanation: "Query profiling means monitoring what SQL queries EF Core generates. You can enable EF Core logging to see queries in console, use SQL Server Profiler, or tools like MiniProfiler. This helps you spot N+1 problems and other inefficiencies. It's like checking your car's fuel efficiency - you need to measure to know if there's a problem."
                                }
                            ]
                        },
                        {
                            id: 30,
                            question: "Explain eager loading, lazy loading, and explicit loading in EF Core.",
                            suggestedAnswer: "These are three strategies for loading related data. Eager loading uses Include() or ThenInclude() to load related entities in the initial query with JOINs. Lazy loading automatically loads navigation properties when accessed, requiring proxies and causing additional queries. Explicit loading uses Entry().Collection().Load() or Entry().Reference().Load() to manually load related data after the initial query. Eager loading is best for most scenarios as it's predictable and avoids N+1 problems. Lazy loading is convenient but can cause performance issues and is opt-in in EF Core. Explicit loading is useful when you conditionally need related data based on business logic. At BIPO, we primarily use eager loading with Include() for predictable performance, and explicit loading when we need to load related data based on user permissions or conditional logic that can't be determined upfront.",
                            bulletPoints: [
                                "Eager: Include() loads related data upfront with JOINs",
                                "Lazy: auto-loads when accessed, requires proxies, causes extra queries",
                                "Explicit: manually load with Entry().Collection().Load()",
                                "Eager loading: best for most scenarios, predictable",
                                "Lazy loading: convenient but risky, opt-in in EF Core",
                                "Explicit loading: useful for conditional loading",
                                "Choose based on access patterns and performance needs"
                            ],
                            keyConcepts: [
                                {
                                    name: "Navigation Properties",
                                    explanation: "Navigation properties are properties on your entity classes that reference related entities. For example, an Order entity might have a Customer navigation property. These properties let you navigate relationships in your object graph. How these properties get populated (eager, lazy, or explicit) determines when and how related data is loaded from the database."
                                },
                                {
                                    name: "Proxies",
                                    explanation: "Proxies are dynamically generated classes that inherit from your entities and override navigation properties to enable lazy loading. When you access a navigation property, the proxy intercepts it and loads data from the database. In EF Core, you need to install Microsoft.EntityFrameworkCore.Proxies and call UseLazyLoadingProxies() to enable this. It's like having a middleman who fetches data on demand."
                                },
                                {
                                    name: "Loading Strategy Trade-offs",
                                    explanation: "Each loading strategy has trade-offs. Eager loading makes one larger query upfront - good for predictable performance but might load unneeded data. Lazy loading makes many small queries as needed - convenient but unpredictable and prone to N+1. Explicit loading gives you control but requires more code. Choose based on your access patterns: if you always need the data, eager load it; if you rarely need it, explicitly load when necessary."
                                }
                            ]
                        },
                        {
                            id: 31,
                            question: "How do you implement database migrations in EF Core?",
                            suggestedAnswer: "Migrations track and apply database schema changes. Create a migration with 'dotnet ef migrations add MigrationName' after modifying entity classes. This generates a migration file with Up() and Down() methods. Apply migrations with 'dotnet ef database update' to update the database, or 'dotnet ef database update PreviousMigration' to rollback. You can generate SQL scripts with 'dotnet ef migrations script' for production deployments. Migrations are stored in code and version controlled. For production, use SQL scripts rather than automatic updates for safety. You can also apply migrations programmatically with context.Database.Migrate() at startup. At Liven Group during our .NET 6 migration, we used migrations to gradually evolve the schema across multiple databases. At BIPO, we generate SQL scripts from migrations and apply them through our CI/CD pipeline with approval gates for production.",
                            bulletPoints: [
                                "Create: dotnet ef migrations add MigrationName",
                                "Apply: dotnet ef database update",
                                "Rollback: dotnet ef database update PreviousMigration",
                                "Generate SQL: dotnet ef migrations script",
                                "Migrations stored in code, version controlled",
                                "Use SQL scripts for production (safer than auto-update)",
                                "Can apply programmatically with context.Database.Migrate()"
                            ],
                            keyConcepts: [
                                {
                                    name: "Up and Down Methods",
                                    explanation: "Each migration has Up() and Down() methods. Up() applies the migration (e.g., creates a table), Down() reverts it (e.g., drops the table). This lets you move forward or backward through your schema history. It's like having undo/redo for your database structure. EF Core generates these methods automatically based on your entity changes."
                                },
                                {
                                    name: "Migration History Table",
                                    explanation: "EF Core maintains a __EFMigrationsHistory table in your database that tracks which migrations have been applied. When you run 'database update', EF Core checks this table and applies any pending migrations. This ensures migrations are only applied once and in the correct order. It's like a logbook that records what changes have been made."
                                },
                                {
                                    name: "Production Migration Strategy",
                                    explanation: "For production, never use automatic migrations at startup - it's risky. Instead, generate SQL scripts from migrations, review them, test in staging, and apply through controlled deployment processes. This gives you visibility and control over schema changes. Some teams use database migration tools like DbUp or Flyway for additional control. It's like having a checklist and approval process for important changes."
                                }
                            ]
                        },
                        {
                            id: 32,
                            question: "What are indexes in SQL and how do you create them in EF Core?",
                            suggestedAnswer: "Indexes are database structures that speed up data retrieval by creating a sorted lookup table for specific columns. They're like a book's index - instead of scanning every page, you look up the topic and jump to the right page. In EF Core, create indexes using fluent API with HasIndex() in OnModelCreating, or use [Index] attribute on entity classes. You can create single-column or composite indexes, unique indexes, and filtered indexes. Indexes speed up queries but slow down inserts/updates and use storage. Index foreign keys, frequently queried columns, and columns used in WHERE, JOIN, and ORDER BY clauses. Avoid over-indexing. At Liven Group, I added indexes on order timestamps and restaurant IDs for dashboard queries, improving response times from seconds to milliseconds. At BIPO, we index employee numbers, email addresses, and frequently filtered fields like country and department.",
                            bulletPoints: [
                                "Indexes speed up queries by creating sorted lookups",
                                "Create with HasIndex() in OnModelCreating or [Index] attribute",
                                "Types: single-column, composite, unique, filtered",
                                "Index foreign keys and frequently queried columns",
                                "Indexes speed reads but slow writes and use storage",
                                "Index columns in WHERE, JOIN, ORDER BY clauses",
                                "Avoid over-indexing - balance read vs write performance"
                            ],
                            keyConcepts: [
                                {
                                    name: "Clustered vs Non-Clustered Index",
                                    explanation: "A clustered index determines the physical order of data in the table - there can only be one per table, usually the primary key. Non-clustered indexes create separate structures pointing to the data - you can have many of these. It's like the difference between organizing books by author on the shelf (clustered) versus having a card catalog that points to where books are (non-clustered)."
                                },
                                {
                                    name: "Composite Index",
                                    explanation: "A composite index covers multiple columns together. The order matters - an index on (LastName, FirstName) works for queries filtering by LastName or both, but not just FirstName. Use composite indexes when you frequently query multiple columns together. It's like a phone book sorted by last name then first name - you can find 'Smith, John' but can't efficiently find all Johns."
                                },
                                {
                                    name: "Index Overhead",
                                    explanation: "Every index speeds up reads but slows down writes because the index must be updated when data changes. Indexes also consume disk space. Too many indexes can hurt performance more than help. Analyze your query patterns and index strategically. It's like having too many bookmarks - they help find things but make the book heavier and harder to update."
                                }
                            ]
                        },
                        {
                            id: 33,
                            question: "Explain query execution plans and how to analyze them for optimization.",
                            suggestedAnswer: "A query execution plan shows how SQL Server executes a query - what indexes it uses, how it joins tables, and where it spends time. View plans in SQL Server Management Studio with 'Display Estimated Execution Plan' or 'Include Actual Execution Plan'. Look for table scans (bad - reads entire table), index seeks (good - uses index), high-cost operations, and missing index suggestions. Key metrics: relative cost percentages, number of rows, and actual vs estimated rows. Common issues: table scans instead of index seeks, key lookups, implicit conversions, and parameter sniffing. At Liven Group, I used execution plans to identify missing indexes on order queries and found a table scan on a million-row table that was fixed with an index, reducing query time from 5 seconds to 50ms. At BIPO, we regularly analyze execution plans for payroll calculation queries to ensure they scale across countries.",
                            bulletPoints: [
                                "Shows how SQL Server executes a query",
                                "View in SSMS with 'Display Execution Plan'",
                                "Look for: table scans (bad), index seeks (good)",
                                "Check relative cost percentages and row counts",
                                "Common issues: missing indexes, key lookups, implicit conversions",
                                "SQL Server suggests missing indexes",
                                "Compare estimated vs actual rows for statistics issues"
                            ],
                            keyConcepts: [
                                {
                                    name: "Table Scan vs Index Seek",
                                    explanation: "A table scan reads every row in a table to find matches - slow for large tables. An index seek uses an index to jump directly to matching rows - much faster. In execution plans, table scans appear as thick arrows and high costs. If you see table scans on large tables, you probably need an index. It's like reading an entire dictionary versus looking up a word in the index."
                                },
                                {
                                    name: "Key Lookup",
                                    explanation: "A key lookup happens when an index doesn't contain all needed columns, so SQL Server must look up additional data from the table. This is expensive. Fix it by creating a covering index (includes all needed columns) or using INCLUDE in the index. It's like finding a book in the card catalog but then having to walk to the shelf to get it - an extra step that slows things down."
                                },
                                {
                                    name: "Parameter Sniffing",
                                    explanation: "Parameter sniffing is when SQL Server creates an execution plan based on the first parameter values it sees, which might not be optimal for other values. This can cause performance issues if the first execution had atypical parameters. Solutions include query hints, recompiling, or using OPTIMIZE FOR. It's like tailoring a suit for the first person who walks in, then making everyone else wear that same size."
                                }
                            ]
                        },
                        {
                            id: 34,
                            question: "How do you implement transactions in EF Core?",
                            suggestedAnswer: "Transactions ensure multiple database operations succeed or fail together (ACID properties). EF Core automatically wraps SaveChanges() in a transaction. For explicit transactions, use context.Database.BeginTransaction(), perform operations, then call transaction.Commit() or transaction.Rollback(). Use 'using' statements for automatic disposal. For distributed transactions across multiple contexts or databases, use TransactionScope. You can also use database transactions with ExecuteSqlRaw. Set isolation levels to control concurrent access behavior. At BIPO, we use explicit transactions when processing payroll - we update employee records, create payment entries, and log audit trails all in one transaction, ensuring data consistency. If any step fails, everything rolls back. For multi-database scenarios like updating both SQL Server and MongoDB, we use the Saga pattern instead of distributed transactions.",
                            bulletPoints: [
                                "SaveChanges() automatically uses a transaction",
                                "Explicit: BeginTransaction(), Commit(), Rollback()",
                                "Use 'using' statements for automatic disposal",
                                "TransactionScope for distributed transactions",
                                "Set isolation levels for concurrency control",
                                "Transactions ensure ACID properties",
                                "Keep transactions short to avoid locking"
                            ],
                            keyConcepts: [
                                {
                                    name: "ACID Properties",
                                    explanation: "ACID stands for Atomicity (all or nothing), Consistency (data remains valid), Isolation (transactions don't interfere), and Durability (committed changes persist). Transactions guarantee these properties. For example, transferring money between accounts must be atomic - both debit and credit happen, or neither does. It's like a package deal - you get everything or nothing."
                                },
                                {
                                    name: "Isolation Levels",
                                    explanation: "Isolation levels control how transactions interact with concurrent operations. Read Uncommitted allows dirty reads, Read Committed prevents them, Repeatable Read prevents non-repeatable reads, Serializable prevents phantom reads. Higher isolation means more consistency but more locking and less concurrency. Choose based on your consistency requirements. It's like privacy settings - more privacy means less interaction with others."
                                },
                                {
                                    name: "Distributed Transactions",
                                    explanation: "Distributed transactions span multiple databases or services. They're complex and can cause performance issues. TransactionScope in .NET coordinates them, but many modern systems avoid distributed transactions in favor of eventual consistency patterns like Saga or event sourcing. It's like coordinating multiple people to do things simultaneously - possible but complicated, so sometimes it's better to do things in sequence with compensation if something fails."
                                }
                            ]
                        },
                        {
                            id: 35,
                            question: "What are the differences between AsNoTracking() and regular queries in EF Core?",
                            suggestedAnswer: "Regular queries enable change tracking - EF Core keeps a snapshot of entity values to detect changes for SaveChanges(). AsNoTracking() disables this, making queries faster and using less memory but preventing updates to those entities. Use AsNoTracking() for read-only scenarios like displaying lists, reports, or API responses where you won't modify data. Regular queries are needed when you'll update entities. AsNoTracking queries are 2-3x faster and use significantly less memory for large result sets. You can set AsNoTracking as default with ChangeTracker.QueryTrackingBehavior. At BIPO, we use AsNoTracking() for all read-only API endpoints and reports, significantly reducing memory usage in our invoice list endpoints that return hundreds of records. We only use tracking queries when we need to update entities.",
                            bulletPoints: [
                                "Regular queries: enable change tracking for updates",
                                "AsNoTracking(): no change tracking, read-only, faster",
                                "AsNoTracking() is 2-3x faster and uses less memory",
                                "Use AsNoTracking() for read-only scenarios",
                                "Use regular queries when updating entities",
                                "Can set as default with QueryTrackingBehavior",
                                "AsNoTracking() entities can't be updated via SaveChanges()"
                            ],
                            keyConcepts: [
                                {
                                    name: "Change Tracking Snapshot",
                                    explanation: "When EF Core tracks entities, it keeps a snapshot of their original values in memory. When you call SaveChanges(), it compares current values to the snapshot to generate UPDATE statements. This snapshot consumes memory and CPU. For 1000 entities, you're storing 2000 copies in memory (original + current). AsNoTracking() skips this entirely."
                                },
                                {
                                    name: "Identity Map",
                                    explanation: "EF Core's change tracker also maintains an identity map ensuring you get the same object instance for the same database row within a context. This prevents duplicate objects but adds overhead. AsNoTracking() bypasses this - you might get multiple instances for the same row, but queries are faster. It's like having a registry of who's who versus just meeting people without keeping track."
                                },
                                {
                                    name: "Performance Impact",
                                    explanation: "The performance difference between tracking and non-tracking queries grows with result set size. For 10 rows, the difference is negligible. For 10,000 rows, AsNoTracking() can be dramatically faster and use 50% less memory. Always use AsNoTracking() for large read-only queries. It's like the difference between taking notes in a meeting versus just listening - notes are useful if you'll reference them, but if you're just observing, skip the notes."
                                }
                            ]
                        },
                        {
                            id: 36,
                            question: "How do you write raw SQL queries in EF Core and when would you use them?",
                            suggestedAnswer: "EF Core supports raw SQL with FromSqlRaw() for queries and ExecuteSqlRaw() for commands. FromSqlRaw() returns entities that can be composed with LINQ. Use parameterized queries to prevent SQL injection: FromSqlRaw('SELECT * FROM Users WHERE Id = {0}', userId). For non-entity results, use SqlQuery<T>(). Use raw SQL when: LINQ doesn't translate well, you need database-specific features, performance optimization requires specific SQL, or calling stored procedures. However, prefer LINQ when possible for maintainability and database independence. At Liven Group, I used raw SQL for complex analytics queries with CTEs and window functions that LINQ couldn't express efficiently. At BIPO, we use stored procedures for complex payroll calculations that involve multiple steps and temporary tables, calling them with FromSqlRaw().",
                            bulletPoints: [
                                "FromSqlRaw() for queries returning entities",
                                "ExecuteSqlRaw() for INSERT, UPDATE, DELETE",
                                "SqlQuery<T>() for non-entity results",
                                "Always use parameterized queries (prevent SQL injection)",
                                "Can compose with LINQ after FromSqlRaw()",
                                "Use for: complex queries, stored procedures, performance optimization",
                                "Prefer LINQ when possible for maintainability"
                            ],
                            keyConcepts: [
                                {
                                    name: "SQL Injection",
                                    explanation: "SQL injection is a security vulnerability where attackers insert malicious SQL into your queries. Never concatenate user input into SQL strings. Always use parameterized queries where parameters are passed separately. EF Core's FromSqlRaw with {0} placeholders or FromSqlInterpolated with $'' syntax safely parameterizes values. It's like the difference between letting someone write on your form versus giving them a pre-printed form to fill in specific blanks."
                                },
                                {
                                    name: "Query Composition",
                                    explanation: "After FromSqlRaw(), you can add LINQ operations like Where(), OrderBy(), Take(). EF Core combines your SQL with the LINQ into a single query. This is powerful for building on raw SQL with additional filters. However, the raw SQL must return all columns of the entity. It's like starting with a base recipe and adding your own touches - you get the foundation from SQL and refine with LINQ."
                                },
                                {
                                    name: "Database Independence",
                                    explanation: "Raw SQL ties your code to a specific database dialect. If you switch from SQL Server to PostgreSQL, raw SQL might break. LINQ queries are database-independent - EF Core translates them to the appropriate SQL dialect. Use raw SQL only when necessary, and consider abstracting it behind repositories to isolate database-specific code. It's like writing in English versus using local slang - English works everywhere, slang only works locally."
                                }
                            ]
                        },
                        {
                            id: 37,
                            question: "Explain database normalization and denormalization strategies.",
                            suggestedAnswer: "Normalization organizes data to reduce redundancy and improve integrity through normal forms (1NF, 2NF, 3NF, BCNF). 1NF eliminates repeating groups, 2NF removes partial dependencies, 3NF removes transitive dependencies. Normalized databases avoid data anomalies and save storage but require more joins. Denormalization intentionally adds redundancy for performance by storing computed values or duplicating data to avoid joins. Use normalization for transactional systems (OLTP) where data integrity is critical. Use denormalization for read-heavy systems (OLAP), reporting, or when join performance is problematic. Common denormalization: storing aggregates, duplicating frequently joined data, or using materialized views. At Liven Group, we kept transactional tables normalized but created denormalized reporting tables with pre-computed sales totals. At BIPO, employee data is normalized but we denormalize frequently accessed fields like employee name and department name into payroll records to avoid joins in reports.",
                            bulletPoints: [
                                "Normalization: reduce redundancy, improve integrity",
                                "Normal forms: 1NF (no repeating groups), 2NF (no partial dependencies), 3NF (no transitive dependencies)",
                                "Denormalization: add redundancy for performance",
                                "Normalization: better for OLTP (transactional systems)",
                                "Denormalization: better for OLAP (reporting/analytics)",
                                "Common denormalization: computed values, duplicate data, materialized views",
                                "Balance data integrity vs query performance"
                            ],
                            keyConcepts: [
                                {
                                    name: "Data Anomalies",
                                    explanation: "Unnormalized data causes anomalies: insertion anomaly (can't add data without other data), update anomaly (must update multiple places), deletion anomaly (deleting one thing deletes unrelated data). For example, storing customer address with every order means updating address requires changing all orders. Normalization prevents these by storing each fact once. It's like having one master copy of a document versus many copies that can get out of sync."
                                },
                                {
                                    name: "OLTP vs OLAP",
                                    explanation: "OLTP (Online Transaction Processing) systems handle many small transactions - inserts, updates, deletes. They need normalized data for integrity. OLAP (Online Analytical Processing) systems handle complex queries and reports on large datasets. They benefit from denormalization for query speed. It's like the difference between a busy checkout counter (OLTP - many quick transactions) versus a research library (OLAP - complex analysis of lots of data)."
                                },
                                {
                                    name: "Materialized Views",
                                    explanation: "Materialized views are pre-computed query results stored as tables. They're a form of denormalization that speeds up complex queries by storing the results. You refresh them periodically or on-demand. They trade storage and staleness for query speed. It's like having a summary report ready to go versus generating it from scratch each time someone asks for it."
                                }
                            ]
                        },
                        {
                            id: 38,
                            question: "How do you implement soft deletes in EF Core?",
                            suggestedAnswer: "Soft deletes mark records as deleted without actually removing them, usually with an IsDeleted flag or DeletedAt timestamp. Implement by adding IsDeleted property to entities, creating a query filter in OnModelCreating with HasQueryFilter(e => !e.IsDeleted) to automatically exclude soft-deleted records, and overriding SaveChanges() to set IsDeleted instead of deleting. You can use interfaces like ISoftDelete for consistency. For audit trails, also track DeletedBy and DeletedAt. Query filters apply globally but can be ignored with IgnoreQueryFilters(). Soft deletes enable data recovery, audit trails, and maintaining referential integrity. At BIPO, we implement soft deletes on all major entities for compliance and audit requirements, allowing us to recover accidentally deleted data and maintain complete history for HR regulations across multiple countries.",
                            bulletPoints: [
                                "Add IsDeleted or DeletedAt property to entities",
                                "Use HasQueryFilter() to exclude soft-deleted records",
                                "Override SaveChanges() to set IsDeleted instead of deleting",
                                "Use ISoftDelete interface for consistency",
                                "Track DeletedBy and DeletedAt for audit",
                                "Use IgnoreQueryFilters() to include soft-deleted records",
                                "Benefits: data recovery, audit trails, referential integrity"
                            ],
                            keyConcepts: [
                                {
                                    name: "Query Filters",
                                    explanation: "Query filters are global filters applied to all queries for an entity type. When you set HasQueryFilter(e => !e.IsDeleted), EF Core automatically adds this WHERE clause to every query. This ensures soft-deleted records are hidden by default throughout your application. You don't need to remember to filter them manually. It's like having automatic spam filtering - emails go to spam automatically without you having to check each one."
                                },
                                {
                                    name: "SaveChanges Override",
                                    explanation: "Overriding SaveChanges() lets you intercept delete operations and convert them to updates that set IsDeleted = true. You check for entities in the Deleted state and change them to Modified with IsDeleted set. This makes soft deletes transparent to the rest of your application - code calls Remove() normally but records are soft-deleted. It's like having a trash can that doesn't actually throw things away, just moves them to a hidden folder."
                                },
                                {
                                    name: "Compliance and Audit",
                                    explanation: "Soft deletes are crucial for compliance in regulated industries. Many regulations require maintaining data history and audit trails. Soft deletes let you track who deleted what and when, and recover data if needed. Hard deletes make this impossible. In HR, financial, and healthcare systems, soft deletes are often mandatory. It's like keeping paper trails for legal purposes - you need to prove what happened and when."
                                }
                            ]
                        },
                        {
                            id: 39,
                            question: "What are stored procedures and how do you call them from EF Core?",
                            suggestedAnswer: "Stored procedures are pre-compiled SQL code stored in the database that can accept parameters and return results. They encapsulate complex logic, improve performance through compilation and caching, and provide security through controlled access. Call them in EF Core using FromSqlRaw() for queries or ExecuteSqlRaw() for commands. For output parameters, use SqlParameter with Direction = ParameterDirection.Output. Map stored procedures to entity types or use SqlQuery<T>() for custom result types. Stored procedures are useful for complex business logic, batch operations, or when DBAs manage database code separately. However, they reduce portability and make testing harder. At Liven Group, we used stored procedures for complex sales reporting with multiple CTEs. At BIPO, we have stored procedures for multi-step payroll calculations that involve temporary tables and complex tax logic that's easier to maintain in SQL.",
                            bulletPoints: [
                                "Pre-compiled SQL code stored in database",
                                "Call with FromSqlRaw() or ExecuteSqlRaw()",
                                "Use SqlParameter for input/output parameters",
                                "Benefits: performance, security, encapsulation",
                                "Drawbacks: reduced portability, harder testing",
                                "Useful for: complex logic, batch operations, DBA-managed code",
                                "Can return entities or custom result types"
                            ],
                            keyConcepts: [
                                {
                                    name: "Pre-compilation",
                                    explanation: "Stored procedures are compiled when created, not every time they run. The database creates an execution plan and caches it, making subsequent calls faster. Dynamic SQL is compiled each time. This performance benefit is less significant in modern databases with good query plan caching, but stored procedures still have an edge for complex operations. It's like having a recipe memorized versus reading it each time you cook."
                                },
                                {
                                    name: "Security Benefits",
                                    explanation: "Stored procedures can enhance security by granting users permission to execute procedures without direct table access. This prevents SQL injection and limits what operations users can perform. You can also audit procedure calls. However, this security model is less common in modern applications that use application-level security. It's like having a receptionist who can make appointments for you versus giving you direct access to the calendar."
                                },
                                {
                                    name: "Portability Trade-off",
                                    explanation: "Stored procedures tie your application to a specific database. Switching from SQL Server to PostgreSQL means rewriting procedures. They also make testing harder since you need a database to run them. Modern approaches favor keeping logic in application code for portability and testability. Use stored procedures when performance or database-side logic is critical, but understand the trade-offs. It's like building a custom solution versus using standard parts - custom might be better but harder to replace."
                                }
                            ]
                        },
                        {
                            id: 40,
                            question: "How do you handle concurrency conflicts in EF Core?",
                            suggestedAnswer: "Concurrency conflicts occur when multiple users modify the same data simultaneously. EF Core supports optimistic concurrency using concurrency tokens - typically a RowVersion/Timestamp column or properties marked with [ConcurrencyCheck]. When SaveChanges() detects a conflict (data changed since you loaded it), it throws DbUpdateConcurrencyException. Handle this by: refreshing data and retrying, showing conflict to user for resolution, or implementing last-write-wins. Configure concurrency tokens with IsRowVersion() or IsConcurrencyToken() in fluent API. For pessimistic concurrency, use database locks with transactions and isolation levels. At BIPO, we use RowVersion on critical entities like payroll records. When conflicts occur, we reload the entity with current values, show both versions to the user, and let them decide how to merge changes. This prevents one user's changes from silently overwriting another's.",
                            bulletPoints: [
                                "Optimistic concurrency: detect conflicts at save time",
                                "Use RowVersion/Timestamp or [ConcurrencyCheck] properties",
                                "DbUpdateConcurrencyException thrown on conflict",
                                "Handle by: refresh and retry, user resolution, last-write-wins",
                                "Configure with IsRowVersion() or IsConcurrencyToken()",
                                "Pessimistic concurrency: use database locks",
                                "Choose strategy based on conflict likelihood and business rules"
                            ],
                            keyConcepts: [
                                {
                                    name: "Optimistic vs Pessimistic Concurrency",
                                    explanation: "Optimistic concurrency assumes conflicts are rare - you don't lock data, just detect conflicts when saving. Pessimistic concurrency assumes conflicts are common - you lock data when reading so others can't modify it. Optimistic is better for web applications with many users and low conflict probability. Pessimistic is better for high-conflict scenarios but reduces concurrency. It's like assuming your parking spot will be available (optimistic) versus reserving it (pessimistic)."
                                },
                                {
                                    name: "RowVersion/Timestamp",
                                    explanation: "RowVersion (SQL Server) or Timestamp is a special column that automatically increments with each update. EF Core includes this value in UPDATE's WHERE clause. If the value changed since you loaded the row, the UPDATE affects 0 rows and EF Core throws an exception. This reliably detects conflicts without checking every column. It's like having a version number on a document - you can tell if someone edited it since you last saw it."
                                },
                                {
                                    name: "Conflict Resolution Strategies",
                                    explanation: "When conflicts occur, you have options: Client wins (overwrite database), Database wins (discard changes), Merge (combine both changes), or User decides (show conflict and let them choose). The right strategy depends on your business rules. Financial data might require user resolution, while non-critical data might use last-write-wins. It's like deciding who gets the last piece of cake - sometimes first come first served, sometimes you split it, sometimes you ask who wants it more."
                                }
                            ]
                        }
                    ]
                },
                {
                    id: 4,
                    name: "React & TypeScript Frontend",
                    questions: [
                        {
                            id: 41,
                            question: "What are React Hooks and explain the most commonly used ones (useState, useEffect, useContext)?",
                            suggestedAnswer: "React Hooks are functions that let you use state and other React features in functional components without writing classes. useState manages component state, returning current state and a setter function. useEffect handles side effects like data fetching, subscriptions, or DOM manipulation, running after render and optionally cleaning up. useContext accesses context values without prop drilling. Hooks must be called at the top level, not inside loops or conditions. They enable code reuse through custom hooks. Other common hooks include useReducer for complex state logic, useRef for mutable references, and useMemo/useCallback for performance. At BIPO, we use hooks extensively in our React Native mobile app and web dashboard. useState manages form inputs and UI state, useEffect fetches employee data from APIs, and useContext provides authentication and theme data throughout the app without passing props through every component.",
                            bulletPoints: [
                                "useState: manages component state",
                                "useEffect: handles side effects and lifecycle",
                                "useContext: accesses context without prop drilling",
                                "Must be called at top level (not in loops/conditions)",
                                "Enable code reuse through custom hooks",
                                "Other hooks: useReducer, useRef, useMemo, useCallback",
                                "Replaced class components for most use cases"
                            ],
                            keyConcepts: [
                                {
                                    name: "State Management",
                                    explanation: "State is data that changes over time in your component. useState gives you a state variable and a function to update it. When state changes, React re-renders the component. Unlike regular variables, state persists between renders. It's like having a notepad that remembers information even after you look away and look back."
                                },
                                {
                                    name: "Side Effects",
                                    explanation: "Side effects are operations that affect things outside the component's render function - API calls, timers, subscriptions, DOM manipulation. useEffect runs these after render. You can return a cleanup function to undo effects (like canceling subscriptions). The dependency array controls when effects run. It's like cleaning up after yourself - you set something up, and when you're done, you clean it up."
                                },
                                {
                                    name: "Prop Drilling",
                                    explanation: "Prop drilling is passing props through many component layers to reach a deeply nested component. It's tedious and makes code harder to maintain. useContext solves this by letting any component access context values directly, without passing through intermediaries. It's like having a company-wide announcement system versus passing messages person-to-person."
                                }
                            ]
                        },
                        {
                            id: 42,
                            question: "Explain the difference between useMemo and useCallback hooks.",
                            suggestedAnswer: "useMemo and useCallback are optimization hooks that prevent unnecessary recalculations and re-renders. useMemo memoizes a computed value, recalculating only when dependencies change. Use it for expensive calculations. useCallback memoizes a function, returning the same function instance unless dependencies change. Use it when passing callbacks to optimized child components that rely on reference equality. Both take a function and dependency array. The key difference: useMemo returns the result of calling the function, useCallback returns the function itself. Don't overuse them - they add overhead. Only use when profiling shows performance issues. At BIPO, we use useMemo for expensive payroll calculations that filter and aggregate large employee datasets, and useCallback for event handlers passed to memoized child components in our data tables to prevent unnecessary re-renders of table rows.",
                            bulletPoints: [
                                "useMemo: memoizes computed values",
                                "useCallback: memoizes functions",
                                "useMemo returns function result, useCallback returns function itself",
                                "Both take dependencies array",
                                "Use for: expensive calculations, preventing re-renders",
                                "Don't overuse - they add overhead",
                                "Only optimize when profiling shows issues"
                            ],
                            keyConcepts: [
                                {
                                    name: "Memoization",
                                    explanation: "Memoization is caching the result of expensive operations so you don't recalculate them every render. React remembers the previous result and dependencies. If dependencies haven't changed, it returns the cached result instead of recalculating. It's like remembering the answer to a math problem instead of solving it again every time someone asks."
                                },
                                {
                                    name: "Reference Equality",
                                    explanation: "In JavaScript, functions and objects are compared by reference, not value. A new function created each render is different from the previous one, even if the code is identical. This causes child components using React.memo to re-render unnecessarily. useCallback prevents this by returning the same function reference. It's like the difference between 'is this the same person?' versus 'do these people look alike?'"
                                },
                                {
                                    name: "Premature Optimization",
                                    explanation: "Adding useMemo/useCallback everywhere actually hurts performance because memoization has overhead. Only use them when you've profiled and found actual performance problems. Most components render fast enough without optimization. It's like adding insurance to everything you own - the insurance itself costs money, so only insure valuable things."
                                }
                            ]
                        },
                        {
                            id: 43,
                            question: "How do you manage global state in React applications (Context API, Redux, Zustand)?",
                            suggestedAnswer: "Global state management solutions share data across components without prop drilling. Context API is built into React - create a context, provide values at the top level, and consume with useContext. It's simple but can cause unnecessary re-renders. Redux is a predictable state container with actions, reducers, and a single store. It has more boilerplate but excellent dev tools and middleware support. Zustand is a lightweight alternative with minimal boilerplate, using hooks and not requiring providers. Choose based on complexity: Context for simple cases, Redux for large apps with complex state logic and time-travel debugging, Zustand for medium apps wanting simplicity. At BIPO, we use Context API for authentication and theme state, and Zustand for more complex application state like employee filters and form data. For the React Native mobile app, Zustand's simplicity and small bundle size were perfect for our needs.",
                            bulletPoints: [
                                "Context API: built-in, simple, can cause re-renders",
                                "Redux: predictable, more boilerplate, great dev tools",
                                "Zustand: lightweight, minimal boilerplate, hooks-based",
                                "Context: good for simple global state",
                                "Redux: good for complex state with middleware",
                                "Zustand: good middle ground with simplicity",
                                "Choose based on app complexity and team preference"
                            ],
                            keyConcepts: [
                                {
                                    name: "State Container",
                                    explanation: "A state container is a centralized place to store application state that multiple components need. Instead of lifting state up through many levels, you put it in one place and components access it directly. It's like having a shared filing cabinet that everyone can access, versus passing folders from person to person."
                                },
                                {
                                    name: "Actions and Reducers",
                                    explanation: "In Redux, actions are objects describing what happened (e.g., 'USER_LOGGED_IN'), and reducers are pure functions that take current state and an action, returning new state. This pattern makes state changes predictable and testable. It's like having a ledger where you record every transaction (action) and calculate the new balance (reducer)."
                                },
                                {
                                    name: "Re-render Optimization",
                                    explanation: "Context API re-renders all consuming components when any context value changes. For large apps, this can hurt performance. Solutions include splitting contexts, using selectors, or choosing Redux/Zustand which have built-in optimization. It's like a fire alarm that evacuates the entire building versus one that only evacuates the affected floor."
                                }
                            ]
                        },
                        {
                            id: 44,
                            question: "What is TypeScript and what are its benefits over JavaScript?",
                            suggestedAnswer: "TypeScript is a typed superset of JavaScript that compiles to plain JavaScript. It adds static typing, interfaces, enums, and advanced features while maintaining JavaScript compatibility. Benefits include: catching errors at compile time instead of runtime, better IDE support with IntelliSense and autocomplete, self-documenting code through types, safer refactoring, and improved code quality in large teams. TypeScript prevents common bugs like accessing undefined properties or passing wrong argument types. The type system is optional and gradual - you can adopt it incrementally. At BIPO, we use TypeScript for all React and React Native development. It catches bugs during development, makes our codebase more maintainable across multiple developers, and provides excellent IDE support that speeds up development. The initial learning curve pays off quickly in reduced bugs and better developer experience.",
                            bulletPoints: [
                                "Typed superset of JavaScript, compiles to JS",
                                "Static typing catches errors at compile time",
                                "Better IDE support: IntelliSense, autocomplete, refactoring",
                                "Self-documenting code through type annotations",
                                "Prevents common bugs (undefined, wrong types)",
                                "Optional and gradual adoption",
                                "Improves code quality in large teams"
                            ],
                            keyConcepts: [
                                {
                                    name: "Static vs Dynamic Typing",
                                    explanation: "Static typing (TypeScript) checks types at compile time before code runs. Dynamic typing (JavaScript) checks at runtime. Static typing catches errors earlier and provides better tooling, but requires more upfront work. It's like spell-check while you type versus finding spelling errors when you print the document."
                                },
                                {
                                    name: "Type Inference",
                                    explanation: "TypeScript can often infer types without explicit annotations. If you write const name = 'John', TypeScript knows name is a string. You don't need to write const name: string = 'John'. This reduces verbosity while maintaining type safety. It's like a smart assistant who understands context without you explaining everything."
                                },
                                {
                                    name: "Gradual Adoption",
                                    explanation: "You can add TypeScript to existing JavaScript projects incrementally. Start with .ts files alongside .js files, gradually converting. Use 'any' type for complex migrations. This makes adoption practical for large codebases. It's like renovating a house one room at a time while still living there, versus moving out and rebuilding everything."
                                }
                            ]
                        },
                        {
                            id: 45,
                            question: "Explain TypeScript generics and provide practical examples.",
                            suggestedAnswer: "Generics are type variables that let you write reusable code that works with multiple types while maintaining type safety. They're like function parameters but for types. Common example: Array<T> where T is the element type. Use generics for functions, interfaces, and classes. Syntax: function identity<T>(arg: T): T { return arg; }. Practical examples: API response types Response<T>, useState<User>(), generic utility functions like filterArray<T>(items: T[], predicate: (item: T) => boolean). Generics enable type-safe collections, reusable components, and flexible APIs. At BIPO, we use generics extensively for API client functions that return different data types, generic table components that work with any data shape, and utility functions for data transformation that maintain type safety across different entity types.",
                            bulletPoints: [
                                "Type variables for reusable, type-safe code",
                                "Syntax: function name<T>(arg: T): T",
                                "Used in functions, interfaces, classes",
                                "Common: Array<T>, Promise<T>, Response<T>",
                                "Enable type-safe collections and utilities",
                                "Constraints: <T extends SomeType>",
                                "Multiple type parameters: <T, U>"
                            ],
                            keyConcepts: [
                                {
                                    name: "Type Parameters",
                                    explanation: "Type parameters (like <T>) are placeholders for actual types that will be provided when the generic is used. When you call identity<string>('hello'), T becomes string. TypeScript infers the type if possible, so identity('hello') also works. It's like a template where you fill in the blanks - the structure is fixed but the content varies."
                                },
                                {
                                    name: "Generic Constraints",
                                    explanation: "Constraints limit what types can be used with a generic using 'extends'. For example, <T extends { id: number }> means T must have an id property. This lets you access properties safely while maintaining flexibility. It's like saying 'this function works with any vehicle, but it must have wheels' - you're flexible but with requirements."
                                },
                                {
                                    name: "Type Safety with Flexibility",
                                    explanation: "Generics provide both type safety and code reuse. Without generics, you'd either use 'any' (losing type safety) or duplicate code for each type. Generics let you write once and use with many types while keeping full type checking. It's like having a universal adapter that works with different plugs but still ensures proper voltage."
                                }
                            ]
                        },
                        {
                            id: 46,
                            question: "How do you type React components, props, and hooks in TypeScript?",
                            suggestedAnswer: "Type React components using React.FC<Props> or function Component(props: Props): JSX.Element. Define props with interfaces or types. For hooks, TypeScript often infers types, but you can be explicit: useState<User | null>(null), useRef<HTMLDivElement>(null). Type events as React.ChangeEvent<HTMLInputElement> or React.MouseEvent. For children, use React.ReactNode. For generic components, use generics: function List<T>(props: { items: T[] }). Use Partial<T> for optional props, Pick<T, 'field'> for subsets. At BIPO, we define strict prop interfaces for all components, use discriminated unions for variant props, and leverage TypeScript's utility types. This catches prop errors at compile time and provides excellent autocomplete in our IDE, making development faster and preventing runtime errors from incorrect prop usage.",
                            bulletPoints: [
                                "Components: React.FC<Props> or (props: Props) => JSX.Element",
                                "Props: define with interface or type",
                                "Hooks: useState<Type>, useRef<HTMLElement>",
                                "Events: React.ChangeEvent, React.MouseEvent",
                                "Children: React.ReactNode",
                                "Generic components: function List<T>(props: { items: T[] })",
                                "Utility types: Partial, Pick, Omit"
                            ],
                            keyConcepts: [
                                {
                                    name: "Props Interface",
                                    explanation: "Defining props with interfaces provides type safety and documentation. interface ButtonProps { text: string; onClick: () => void; disabled?: boolean; } makes it clear what props are required and optional. IDEs show this information when you use the component. It's like having a contract that specifies exactly what the component needs."
                                },
                                {
                                    name: "Event Typing",
                                    explanation: "React events have specific types like React.ChangeEvent<HTMLInputElement> for input changes or React.MouseEvent<HTMLButtonElement> for clicks. These types provide access to event properties with full type safety. Using the correct event type prevents errors and enables autocomplete for event properties. It's like having specialized tools for different jobs instead of one generic tool."
                                },
                                {
                                    name: "Generic Components",
                                    explanation: "Generic components work with different data types while maintaining type safety. A generic Table<T> component can display any data type, and TypeScript ensures you're using it correctly. This enables highly reusable components without sacrificing type safety. It's like a universal container that adapts to what you put in it while still keeping track of what's inside."
                                }
                            ]
                        },
                        {
                            id: 47,
                            question: "What is the virtual DOM and how does React's reconciliation algorithm work?",
                            suggestedAnswer: "The virtual DOM is a lightweight JavaScript representation of the actual DOM. When state changes, React creates a new virtual DOM tree, compares it with the previous one (diffing), and calculates the minimum changes needed. Then it updates only those parts of the real DOM (reconciliation). This is faster than manipulating the DOM directly because DOM operations are expensive. React uses a heuristic O(n) algorithm assuming: elements of different types produce different trees, and you can hint at stable elements with keys. Keys help React identify which items changed, were added, or removed in lists. Without keys, React might unnecessarily recreate elements. At BIPO, understanding reconciliation helps us optimize list rendering in our employee tables by using stable keys (employee IDs) and avoiding inline object creation that breaks reference equality.",
                            bulletPoints: [
                                "Virtual DOM: JavaScript representation of real DOM",
                                "Diffing: compare old and new virtual DOM trees",
                                "Reconciliation: update only changed parts of real DOM",
                                "O(n) algorithm using heuristics",
                                "Keys help identify list items across renders",
                                "Avoids expensive direct DOM manipulation",
                                "Different element types cause full subtree recreation"
                            ],
                            keyConcepts: [
                                {
                                    name: "DOM Manipulation Cost",
                                    explanation: "Manipulating the real DOM is slow because it triggers reflows and repaints. The browser must recalculate layouts and redraw pixels. React minimizes this by batching updates and only touching the DOM when necessary. The virtual DOM acts as a buffer that lets React optimize these operations. It's like planning all your errands before leaving the house versus making a separate trip for each errand."
                                },
                                {
                                    name: "Diffing Algorithm",
                                    explanation: "React's diffing algorithm compares trees level by level. If elements have different types, React destroys the old tree and builds a new one. If they're the same type, React updates only changed attributes. This heuristic approach is much faster than a perfect algorithm. It's like comparing two versions of a document by looking at each paragraph, not each character."
                                },
                                {
                                    name: "Keys in Lists",
                                    explanation: "Keys tell React which list items are the same across renders. Without keys, React uses index position, which breaks when items reorder. Good keys are stable, unique IDs. Bad keys are array indices or random values. Proper keys prevent unnecessary re-renders and maintain component state. It's like having name tags at a party - you can recognize people even if they move around."
                                }
                            ]
                        },
                        {
                            id: 48,
                            question: "Explain React component lifecycle and how it relates to hooks.",
                            suggestedAnswer: "Class components have lifecycle methods: componentDidMount (after first render), componentDidUpdate (after updates), componentWillUnmount (before removal). Hooks replace these: useEffect with empty deps array runs once like componentDidMount. useEffect with deps runs on mount and when deps change like componentDidUpdate. useEffect cleanup function runs like componentWillUnmount. useLayoutEffect runs synchronously after DOM mutations, like componentDidMount but before paint. Hooks provide more flexibility - you can have multiple useEffects for different concerns, unlike lifecycle methods that handle everything. At BIPO, we use useEffect for data fetching on mount, subscriptions with cleanup, and responding to prop changes. The hooks model is more intuitive than lifecycle methods because effects are organized by concern rather than lifecycle phase.",
                            bulletPoints: [
                                "Class lifecycle: componentDidMount, componentDidUpdate, componentWillUnmount",
                                "useEffect(fn, []) = componentDidMount",
                                "useEffect(fn, [deps]) = componentDidUpdate",
                                "useEffect cleanup = componentWillUnmount",
                                "useLayoutEffect = synchronous, before paint",
                                "Multiple useEffects for different concerns",
                                "Hooks organize by concern, not lifecycle phase"
                            ],
                            keyConcepts: [
                                {
                                    name: "Effect Timing",
                                    explanation: "useEffect runs after render and paint - the browser has already updated the screen. useLayoutEffect runs after render but before paint - synchronously. Use useEffect for most cases (data fetching, subscriptions). Use useLayoutEffect when you need to measure or mutate DOM before the user sees it. It's like the difference between sending a letter after the meeting (useEffect) versus handing it to someone before they leave (useLayoutEffect)."
                                },
                                {
                                    name: "Dependency Array",
                                    explanation: "The dependency array controls when effects run. Empty array [] runs once on mount. Array with values [count, user] runs when those values change. No array runs after every render (usually not what you want). Missing dependencies can cause bugs - use ESLint rules to catch them. It's like setting reminders - you specify what triggers the reminder."
                                },
                                {
                                    name: "Cleanup Functions",
                                    explanation: "Returning a function from useEffect creates a cleanup that runs before the effect runs again and when the component unmounts. Use it to cancel subscriptions, clear timers, or abort fetch requests. This prevents memory leaks and race conditions. It's like turning off the lights when you leave a room - you clean up after yourself."
                                }
                            ]
                        },
                        {
                            id: 49,
                            question: "How do you optimize React application performance (memoization, code splitting, lazy loading)?",
                            suggestedAnswer: "Performance optimization techniques: Use React.memo to prevent re-renders of components when props haven't changed. Use useMemo for expensive calculations and useCallback for stable function references. Implement code splitting with React.lazy() and Suspense to load components on demand, reducing initial bundle size. Use dynamic imports for routes and heavy features. Virtualize long lists with react-window or react-virtualized to render only visible items. Optimize images with lazy loading and proper formats. Avoid inline object/array creation in render. Use production builds. Profile with React DevTools Profiler to find bottlenecks. At BIPO, we code-split by route, virtualize employee lists with thousands of rows, memoize expensive payroll calculations, and lazy load heavy chart libraries. These optimizations reduced our initial load time by 60% and improved list scrolling performance significantly.",
                            bulletPoints: [
                                "React.memo: prevent re-renders when props unchanged",
                                "useMemo/useCallback: cache values and functions",
                                "Code splitting: React.lazy() and Suspense",
                                "Virtualization: render only visible list items",
                                "Lazy load images and heavy components",
                                "Avoid inline object/array creation",
                                "Profile with React DevTools to find bottlenecks"
                            ],
                            keyConcepts: [
                                {
                                    name: "Code Splitting",
                                    explanation: "Code splitting breaks your app into smaller chunks that load on demand. Instead of one huge bundle, users download only what they need initially. Use React.lazy() for component-level splitting and dynamic import() for any code. This dramatically reduces initial load time. It's like downloading a book chapter by chapter as you read, versus downloading the entire book upfront."
                                },
                                {
                                    name: "Virtualization",
                                    explanation: "Virtualization renders only visible items in long lists, not all thousands of items. As you scroll, items are recycled. Libraries like react-window handle this. Without virtualization, rendering 10,000 rows creates 10,000 DOM nodes - slow. With virtualization, you render maybe 20 visible rows. It's like a theater with moving scenery - you only see what's on stage, not everything backstage."
                                },
                                {
                                    name: "Performance Profiling",
                                    explanation: "Don't optimize blindly - profile first to find actual bottlenecks. React DevTools Profiler shows which components render, how long they take, and why they rendered. Optimize the slow parts, not everything. Premature optimization wastes time and adds complexity. It's like fixing the slowest part of your commute first, not optimizing every step."
                                }
                            ]
                        },
                        {
                            id: 50,
                            question: "What are controlled vs uncontrolled components in React?",
                            suggestedAnswer: "Controlled components have their value controlled by React state. The input's value prop is tied to state, and onChange updates state. React is the single source of truth. Uncontrolled components store their own state internally in the DOM. You access values with refs. Controlled components give you full control - validation, formatting, conditional logic. Uncontrolled components are simpler for basic forms but harder to validate or manipulate. Most React forms use controlled components. For file inputs (can't be controlled) or integrating with non-React code, use uncontrolled. At BIPO, we use controlled components for all forms, enabling real-time validation, conditional fields, and complex business logic. For example, our employee form validates as you type, shows/hides fields based on employment type, and formats inputs automatically - all possible because we control the values.",
                            bulletPoints: [
                                "Controlled: value from React state, onChange updates state",
                                "Uncontrolled: value stored in DOM, accessed via refs",
                                "Controlled: React is single source of truth",
                                "Controlled: enables validation, formatting, conditional logic",
                                "Uncontrolled: simpler for basic forms",
                                "Most React forms use controlled components",
                                "File inputs must be uncontrolled"
                            ],
                            keyConcepts: [
                                {
                                    name: "Single Source of Truth",
                                    explanation: "In controlled components, React state is the single source of truth for input values. The DOM reflects state, not the other way around. This makes the data flow predictable and enables features like validation and formatting. It's like having one master copy of a document that everyone references, versus everyone having their own copy that might differ."
                                },
                                {
                                    name: "Refs for Uncontrolled",
                                    explanation: "Uncontrolled components use refs to access DOM values when needed (like on submit). useRef creates a reference to the DOM element. This is simpler than controlled components but gives less control during user interaction. It's like checking your mailbox only when you need something versus monitoring every letter as it arrives."
                                },
                                {
                                    name: "When to Use Each",
                                    explanation: "Use controlled for most forms - you get validation, dynamic behavior, and predictable state. Use uncontrolled for simple forms where you just need the value on submit, file inputs (which must be uncontrolled), or integrating with non-React libraries. The extra code for controlled components is worth it for the control you gain."
                                }
                            ]
                        },
                        {
                            id: 51,
                            question: "How do you handle forms in React (React Hook Form, Formik)?",
                            suggestedAnswer: "Form libraries simplify form management. React Hook Form is lightweight, uses uncontrolled components with refs for performance, and has minimal re-renders. Formik uses controlled components, has more features but more re-renders. Both handle validation (with Yup or Zod schemas), error messages, submission, and field arrays. React Hook Form: useForm() hook, register() for fields, handleSubmit() for submission. Formik: Formik component or useFormik() hook. For simple forms, native React with controlled components works fine. For complex forms with validation, dynamic fields, or field arrays, use a library. At BIPO, we use React Hook Form for its performance and TypeScript support. Our employee onboarding form has 50+ fields with complex validation rules, conditional fields, and file uploads. React Hook Form handles this efficiently with minimal code and excellent performance.",
                            bulletPoints: [
                                "React Hook Form: lightweight, uncontrolled, minimal re-renders",
                                "Formik: controlled components, more features",
                                "Both support validation schemas (Yup, Zod)",
                                "Handle: validation, errors, submission, field arrays",
                                "React Hook Form: register(), handleSubmit()",
                                "Formik: Formik component or useFormik() hook",
                                "Use libraries for complex forms, native React for simple ones"
                            ],
                            keyConcepts: [
                                {
                                    name: "Form Validation",
                                    explanation: "Validation ensures user input meets requirements. Client-side validation provides immediate feedback. Schema validation libraries like Yup or Zod define rules declaratively. Form libraries integrate these schemas, showing errors automatically. Always validate server-side too - client validation is for UX, not security. It's like spell-check while typing (client) plus an editor reviewing your final draft (server)."
                                },
                                {
                                    name: "Re-render Performance",
                                    explanation: "Controlled components re-render on every keystroke because state updates. For large forms, this can be slow. React Hook Form minimizes re-renders by using refs and only re-rendering when necessary. Formik re-renders more but is still fast enough for most forms. Profile your forms if performance is an issue. It's like the difference between recalculating everything versus only recalculating what changed."
                                },
                                {
                                    name: "Field Arrays",
                                    explanation: "Field arrays handle dynamic lists of fields (like adding multiple phone numbers). Form libraries provide utilities for adding, removing, and reordering items while maintaining validation and state. Implementing this manually is complex. It's like having a template for repeating sections of a form that you can duplicate and remove as needed."
                                }
                            ]
                        },
                        {
                            id: 52,
                            question: "Explain error boundaries in React and how to implement them.",
                            suggestedAnswer: "Error boundaries are React components that catch JavaScript errors in their child component tree, log errors, and display fallback UI instead of crashing the whole app. They catch errors during rendering, in lifecycle methods, and in constructors, but not in event handlers, async code, or the error boundary itself. Implement by creating a class component with componentDidCatch() or static getDerivedStateFromError(). There's no hook equivalent yet. Wrap parts of your app with error boundaries to isolate failures. At BIPO, we wrap each major feature section in error boundaries. If the employee list crashes, the navigation and other sections still work. We log errors to our monitoring service and show user-friendly error messages with retry options. This prevents one component's bug from breaking the entire application.",
                            bulletPoints: [
                                "Catch errors in child component tree",
                                "Display fallback UI instead of crashing",
                                "Catch: rendering errors, lifecycle, constructors",
                                "Don't catch: event handlers, async code, error boundary itself",
                                "Implement with componentDidCatch() or getDerivedStateFromError()",
                                "No hook equivalent yet (must use class component)",
                                "Wrap app sections to isolate failures"
                            ],
                            keyConcepts: [
                                {
                                    name: "Graceful Degradation",
                                    explanation: "Error boundaries enable graceful degradation - when something breaks, the app doesn't completely fail. Users see an error message for the broken part but can still use the rest of the app. This is much better than a blank screen or crashed app. It's like a building with fire doors - a fire in one room doesn't burn down the whole building."
                                },
                                {
                                    name: "Error Boundary Limitations",
                                    explanation: "Error boundaries don't catch errors in event handlers (use try-catch), async code (use .catch()), or during server-side rendering. They only catch errors during React's render phase. For event handlers and async code, handle errors explicitly. It's like having a safety net that catches you when you fall off the tightrope, but not when you trip on the platform."
                                },
                                {
                                    name: "Error Logging",
                                    explanation: "Error boundaries are perfect for logging errors to monitoring services like Sentry or LogRocket. componentDidCatch receives the error and component stack, which you can send to your logging service. This helps you discover and fix bugs in production. It's like having security cameras that record incidents so you can review and prevent them."
                                }
                            ]
                        },
                        {
                            id: 53,
                            question: "How do you fetch data in React (useEffect, React Query, SWR)?",
                            suggestedAnswer: "Basic data fetching uses useEffect with fetch or axios, storing data in state. Handle loading and error states manually. React Query and SWR are data fetching libraries that handle caching, refetching, loading states, and errors automatically. React Query: useQuery() hook with query key and fetch function. SWR: useSWR() with key and fetcher. Both provide: automatic caching, background refetching, optimistic updates, pagination, and infinite scroll. Use native useEffect for simple one-time fetches. Use React Query/SWR for complex data fetching with caching needs. At BIPO, we use React Query for all API calls. It caches employee data, automatically refetches when data becomes stale, handles loading and error states, and provides excellent DevTools. This eliminated hundreds of lines of manual caching and state management code.",
                            bulletPoints: [
                                "Basic: useEffect with fetch/axios, manual state management",
                                "React Query: useQuery() with caching and refetching",
                                "SWR: useSWR() with stale-while-revalidate strategy",
                                "Libraries handle: caching, loading, errors, refetching",
                                "Features: pagination, infinite scroll, optimistic updates",
                                "Use useEffect for simple cases, libraries for complex data fetching",
                                "React Query/SWR eliminate manual cache management"
                            ],
                            keyConcepts: [
                                {
                                    name: "Stale-While-Revalidate",
                                    explanation: "SWR's strategy: show cached (stale) data immediately while fetching fresh data in the background. When fresh data arrives, update the UI. This makes apps feel instant while ensuring data freshness. React Query uses similar strategies. It's like reading yesterday's newspaper while today's is being delivered - you get information immediately and updates when available."
                                },
                                {
                                    name: "Query Keys",
                                    explanation: "Query keys identify queries for caching. useQuery(['users', userId], fetchUser) caches by user ID. Different IDs create different cache entries. Keys can be arrays with multiple values for complex queries. This enables automatic cache invalidation and refetching. It's like having a filing system where each folder has a unique label so you can find and update specific items."
                                },
                                {
                                    name: "Automatic Refetching",
                                    explanation: "React Query and SWR automatically refetch data in certain situations: when the window regains focus, when the network reconnects, or at configured intervals. This keeps data fresh without manual intervention. You can configure this behavior per query. It's like having a news app that automatically refreshes when you open it, ensuring you see the latest news."
                                }
                            ]
                        },
                        {
                            id: 54,
                            question: "What is React.memo and when should you use it?",
                            suggestedAnswer: "React.memo is a higher-order component that memoizes a component, preventing re-renders when props haven't changed. It does a shallow comparison of props. Use it for components that render often with the same props, expensive components, or components receiving new object/array references that are actually equal. Don't use it everywhere - it adds overhead. Only use when profiling shows unnecessary re-renders. For custom comparison, pass a comparison function as second argument. React.memo works with functional components; for class components, use PureComponent. At BIPO, we use React.memo on table row components that render hundreds of times. Without memo, editing one row re-rendered all rows. With memo, only the changed row re-renders, dramatically improving performance in our employee lists.",
                            bulletPoints: [
                                "HOC that prevents re-renders when props unchanged",
                                "Shallow comparison of props by default",
                                "Use for: frequently rendered components, expensive renders",
                                "Don't overuse - adds overhead",
                                "Custom comparison: React.memo(Component, arePropsEqual)",
                                "Functional component equivalent of PureComponent",
                                "Profile first to confirm unnecessary re-renders"
                            ],
                            keyConcepts: [
                                {
                                    name: "Shallow Comparison",
                                    explanation: "React.memo compares props using shallow equality - it checks if primitive values are equal and if objects/arrays have the same reference. It doesn't deep-compare object contents. If you pass new object instances with the same data, React.memo won't prevent re-renders. Use useMemo/useCallback to maintain stable references. It's like checking if two boxes are the same box versus checking if they contain the same items."
                                },
                                {
                                    name: "Memoization Overhead",
                                    explanation: "React.memo adds overhead - it must compare props on every render. For fast components, this overhead might be more expensive than just re-rendering. Only use memo when re-rendering is actually expensive or happens frequently. Profile to confirm. It's like using a calculator for simple math - sometimes doing it in your head is faster than getting the calculator out."
                                },
                                {
                                    name: "When Memo Helps",
                                    explanation: "React.memo helps most with: components that render many times (like list items), components with expensive render logic, or components that receive new object references but equivalent data. It's less helpful for components that render rarely or have simple render logic. The key is measuring actual performance impact."
                                }
                            ]
                        },
                        {
                            id: 55,
                            question: "How do you implement routing in React applications (React Router)?",
                            suggestedAnswer: "React Router is the standard routing library for React. Install react-router-dom, wrap your app in BrowserRouter, and define routes with Routes and Route components. Use Link or NavLink for navigation (don't use <a> tags - they cause full page reloads). Access route params with useParams(), navigate programmatically with useNavigate(), and access location with useLocation(). Implement nested routes, protected routes with authentication checks, and lazy loading with React.lazy(). Use Outlet for nested route rendering. For layouts, wrap routes in layout components. At BIPO, we use React Router for our web dashboard with nested routes for different sections, protected routes that redirect to login if unauthenticated, and lazy-loaded routes to reduce initial bundle size. We also use route-based code splitting to load each feature on demand.",
                            bulletPoints: [
                                "Install react-router-dom, wrap in BrowserRouter",
                                "Define routes with Routes and Route components",
                                "Navigate with Link/NavLink, not <a> tags",
                                "Hooks: useParams(), useNavigate(), useLocation()",
                                "Nested routes with Outlet component",
                                "Protected routes with authentication checks",
                                "Lazy load routes with React.lazy()"
                            ],
                            keyConcepts: [
                                {
                                    name: "Client-Side Routing",
                                    explanation: "React Router provides client-side routing - navigation happens without full page reloads. The URL changes, but JavaScript handles rendering the new view. This makes apps feel faster and enables smooth transitions. The browser's back/forward buttons still work. It's like flipping pages in a book versus closing one book and opening another."
                                },
                                {
                                    name: "Route Parameters",
                                    explanation: "Route parameters are dynamic segments in URLs like /users/:userId. The :userId part is a parameter you can access with useParams(). This enables dynamic routing where one route component handles many similar pages. It's like having a template for user profiles where the user ID determines which profile to show."
                                },
                                {
                                    name: "Protected Routes",
                                    explanation: "Protected routes require authentication or authorization. Implement by wrapping routes in a component that checks auth status and redirects to login if unauthorized. This prevents users from accessing pages they shouldn't see. It's like having a bouncer at a VIP section who checks if you're on the list before letting you in."
                                }
                            ]
                        }
                    ]
                },
                {
                    id: 5,
                    name: "Styling & UI Libraries",
                    questions: [
                        {
                            id: 56,
                            question: "What is TailwindCSS and what are its advantages over traditional CSS?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 57,
                            question: "How do you configure and customize TailwindCSS in a React project?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 58,
                            question: "Explain the concept of utility-first CSS and its benefits.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 59,
                            question: "What is NextUI and how does it compare to other component libraries like Material-UI or Ant Design?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 60,
                            question: "How do you create reusable and composable React components?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 61,
                            question: "What are CSS modules and how do they prevent style conflicts?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 62,
                            question: "How do you implement responsive design in React with TailwindCSS?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 63,
                            question: "Explain CSS-in-JS solutions (styled-components, emotion) and their pros/cons.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 64,
                            question: "How do you implement dark mode in a React application?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 65,
                            question: "What are accessibility (a11y) best practices for React components?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        }
                    ]
                },
                {
                    id: 6,
                    name: "Next.js (Bonus)",
                    questions: [
                        {
                            id: 66,
                            question: "What is Next.js and what advantages does it provide over Create React App?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 67,
                            question: "Explain the different rendering methods in Next.js (SSR, SSG, ISR, CSR).",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 68,
                            question: "How does file-based routing work in Next.js?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 69,
                            question: "What are API routes in Next.js and when would you use them?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 70,
                            question: "Explain the App Router vs Pages Router in Next.js 13+.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        }
                    ]
                },
                {
                    id: 7,
                    name: "Authentication & Security",
                    questions: [
                        {
                            id: 71,
                            question: "How do you implement JWT authentication in .NET Core Web API?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 72,
                            question: "Explain the difference between authentication and authorization.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 73,
                            question: "How do you implement role-based and policy-based authorization in .NET Core?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 74,
                            question: "What is OAuth 2.0 and OpenID Connect, and how do you implement them?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 75,
                            question: "How do you securely store and manage sensitive data (passwords, API keys)?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 76,
                            question: "What are common web security vulnerabilities (OWASP Top 10) and how do you prevent them?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 77,
                            question: "How do you implement HTTPS and SSL/TLS in .NET Core applications?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 78,
                            question: "Explain CSRF attacks and how to prevent them in web applications.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 79,
                            question: "How do you handle token refresh in React applications?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 80,
                            question: "What is Azure Active Directory (Azure AD) and how do you integrate it?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        }
                    ]
                },
                {
                    id: 8,
                    name: "Azure Cloud & DevOps",
                    questions: [
                        {
                            id: 81,
                            question: "What Azure services would you use for hosting a .NET Core Web API?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 82,
                            question: "Explain the difference between Azure App Service, Azure Functions, and Azure Container Instances.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 83,
                            question: "How do you implement CI/CD pipelines for .NET Core applications in Azure DevOps?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 84,
                            question: "What is Docker and how do you containerize a .NET Core application?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 85,
                            question: "Explain the basics of Kubernetes and when you would use it.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 86,
                            question: "How do you implement logging and monitoring in Azure (Application Insights, Log Analytics)?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 87,
                            question: "What is Azure Key Vault and how do you use it to manage secrets?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 88,
                            question: "How do you implement distributed tracing in microservices?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 89,
                            question: "Explain Infrastructure as Code (IaC) and tools like Terraform or ARM templates.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 90,
                            question: "How do you implement blue-green or canary deployments in Azure?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        }
                    ]
                },
                {
                    id: 9,
                    name: "Integrations & Scheduled Jobs",
                    questions: [
                        {
                            id: 91,
                            question: "How do you implement scheduled background jobs in .NET Core (Hangfire, Quartz.NET)?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 92,
                            question: "Explain how to integrate payment gateways (Stripe, PayPal) in .NET Core.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 93,
                            question: "How do you implement file import/export functionality (CSV, Excel, PDF)?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 94,
                            question: "What is Azure Service Bus and when would you use it?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 95,
                            question: "How do you implement webhooks in .NET Core applications?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 96,
                            question: "Explain message queues and how to implement them (RabbitMQ, Azure Queue Storage).",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 97,
                            question: "How do you handle third-party API integrations and rate limiting?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 98,
                            question: "What is Azure Blob Storage and how do you use it for file storage?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 99,
                            question: "How do you implement email sending functionality (SendGrid, SMTP)?",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        },
                        {
                            id: 100,
                            question: "Explain event-driven architecture and how to implement it in .NET Core.",
                            suggestedAnswer: "",
                            bulletPoints: [],
                            keyConcepts: []
                        }
                    ]
                }
            ]
        };

        // State Management
        let currentCategoryId = null;
        let currentQuestionId = null;
        let selectedCategoryFilter = 'all';
        let allQuestions = [];
        let sidebarVisible = true;

        // Initialize the application
        function init() {
            buildAllQuestionsList();
            renderSidebar();
            loadFirstQuestion();
        }

        // Toggle sidebar visibility
        function toggleSidebar() {
            const sidebar = document.getElementById('sidebar');
            const toggleBtn = document.getElementById('sidebarToggle');
            
            sidebarVisible = !sidebarVisible;
            
            if (sidebarVisible) {
                sidebar.classList.remove('hidden');
                toggleBtn.classList.remove('visible');
            } else {
                sidebar.classList.add('hidden');
                toggleBtn.classList.add('visible');
            }
        }

        // Build a flat list of all questions with metadata
        function buildAllQuestionsList() {
            allQuestions = [];
            let globalIndex = 1;
            
            interviewData.categories.forEach(category => {
                category.questions.forEach(question => {
                    allQuestions.push({
                        ...question,
                        categoryId: category.id,
                        categoryName: category.name,
                        globalIndex: globalIndex++
                    });
                });
            });
        }

        // Get filtered questions based on category filter
        function getFilteredQuestions() {
            if (selectedCategoryFilter === 'all') {
                return allQuestions;
            }
            return allQuestions.filter(q => q.categoryId === selectedCategoryFilter);
        }

        // Switch between views
        function switchView(view) {
            const questionsView = document.getElementById('questionsView');
            const overviewView = document.getElementById('overviewView');
            const navButtons = document.querySelectorAll('.header-nav-btn');

            if (view === 'questions') {
                questionsView.style.display = 'flex';
                overviewView.classList.remove('active');
                navButtons[0].classList.add('active');
                navButtons[1].classList.remove('active');
            } else {
                questionsView.style.display = 'none';
                overviewView.classList.add('active');
                navButtons[0].classList.remove('active');
                navButtons[1].classList.add('active');
                renderPracticeOverview();
            }
        }

        // Render practice overview
        function renderPracticeOverview() {
            renderOverviewStats();
            renderOverviewTable();
        }

        // Render overview statistics
        function renderOverviewStats() {
            const statsContainer = document.getElementById('overviewStats');
            
            let totalQuestions = 0;
            let totalPractice = 0;
            let questionsWithPractice = 0;
            let questionsNeedingPractice = 0;

            interviewData.categories.forEach(category => {
                category.questions.forEach(question => {
                    totalQuestions++;
                    const suggestedCount = getCounter(question.id, 'suggested');
                    const bulletCount = getCounter(question.id, 'bullet');
                    const totalCount = suggestedCount + bulletCount;
                    
                    totalPractice += totalCount;
                    
                    if (totalCount > 0) {
                        questionsWithPractice++;
                    } else {
                        questionsNeedingPractice++;
                    }
                });
            });

            statsContainer.innerHTML = `
                <div class="stat-card">
                    <h4>Total Questions</h4>
                    <div class="stat-value">${totalQuestions}</div>
                </div>
                <div class="stat-card">
                    <h4>Total Practice Sessions</h4>
                    <div class="stat-value">${totalPractice}</div>
                </div>
                <div class="stat-card">
                    <h4>Questions Practiced</h4>
                    <div class="stat-value">${questionsWithPractice}</div>
                </div>
                <div class="stat-card">
                    <h4>Need Practice</h4>
                    <div class="stat-value">${questionsNeedingPractice}</div>
                </div>
            `;
        }

        // Render overview table
        function renderOverviewTable() {
            const overviewContent = document.getElementById('overviewContent');
            let html = '';

            interviewData.categories.forEach(category => {
                html += `
                    <div class="overview-category">
                        <div class="overview-table">
                            <div class="overview-category-header">${category.name}</div>
                `;

                category.questions.forEach(question => {
                    const suggestedCount = getCounter(question.id, 'suggested');
                    const bulletCount = getCounter(question.id, 'bullet');
                    const totalCount = suggestedCount + bulletCount;
                    
                    let badgeClass = '';
                    if (totalCount === 0) badgeClass = 'low';
                    else if (totalCount < 5) badgeClass = 'medium';
                    else badgeClass = 'high';

                    html += `
                        <div class="overview-question" onclick="navigateToQuestion(${category.id}, ${question.id})">
                            <div class="overview-question-text">${question.question}</div>
                            <div class="overview-practice-count">
                                <span>Suggested: <span class="practice-badge ${badgeClass}">${suggestedCount}x</span></span>
                                <span>Bullet: <span class="practice-badge ${badgeClass}">${bulletCount}x</span></span>
                            </div>
                        </div>
                    `;
                });

                html += `
                        </div>
                    </div>
                `;
            });

            overviewContent.innerHTML = html;
        }

        // Navigate to a specific question from overview
        function navigateToQuestion(categoryId, questionId) {
            switchView('questions');
            loadQuestion(categoryId, questionId);
        }

        // Render sidebar with category filters and all questions
        function renderSidebar() {
            const sidebar = document.getElementById('sidebar');
            
            // Build category filter chips
            let categoryChipsHTML = `
                <div class="category-filter">
                    <div class="category-filter-title">Filter by Category:</div>
                    <div class="category-chips">
                        <div class="category-chip ${selectedCategoryFilter === 'all' ? 'active' : ''}" 
                             onclick="filterByCategory('all')">
                            All
                        </div>
            `;
            
            interviewData.categories.forEach(category => {
                categoryChipsHTML += `
                    <div class="category-chip ${selectedCategoryFilter === category.id ? 'active' : ''}" 
                         onclick="filterByCategory(${category.id})">
                        ${category.name}
                    </div>
                `;
            });
            
            categoryChipsHTML += `
                    </div>
                </div>
            `;

            // Build question list
            const filteredQuestions = getFilteredQuestions();
            let questionsHTML = `
                <div class="question-counter">
                    Showing <strong>${filteredQuestions.length}</strong> of <strong>${allQuestions.length}</strong> questions
                </div>
                <div class="question-list">
            `;

            filteredQuestions.forEach(question => {
                const isActive = question.categoryId === currentCategoryId && question.id === currentQuestionId;
                const suggestedCount = getCounter(question.id, 'suggested');
                const bulletCount = getCounter(question.id, 'bullet');
                
                questionsHTML += `
                    <div class="question-item ${isActive ? 'active' : ''}" 
                         onclick="loadQuestionById(${question.id})"
                         data-question-id="${question.id}">
                        <div class="question-number">${question.globalIndex}</div>
                        <div class="question-text">
                            ${question.question}
                            <div class="question-category-tag">${question.categoryName}</div>
                            <div class="question-practice-info">
                                <span class="practice-mini-badge ${suggestedCount === 0 ? 'zero' : ''}">ðŸ“ ${suggestedCount}</span>
                                <span class="practice-mini-badge ${bulletCount === 0 ? 'zero' : ''}">ðŸŽ¯ ${bulletCount}</span>
                            </div>
                        </div>
                    </div>
                `;
            });

            questionsHTML += `</div>`;

            sidebar.innerHTML = categoryChipsHTML + questionsHTML;
        }

        // Filter questions by category
        function filterByCategory(categoryId) {
            selectedCategoryFilter = categoryId;
            renderSidebar();
        }

        // Load question by ID (finds the category automatically)
        function loadQuestionById(questionId) {
            const questionData = allQuestions.find(q => q.id === questionId);
            if (questionData) {
                loadQuestion(questionData.categoryId, questionId);
                // Auto-hide sidebar after selecting a question
                if (sidebarVisible) {
                    toggleSidebar();
                }
            }
        }

        // Load first question on init
        function loadFirstQuestion() {
            if (allQuestions.length > 0) {
                const firstQuestion = allQuestions[0];
                loadQuestion(firstQuestion.categoryId, firstQuestion.id);
                // Auto-hide sidebar on initial load
                if (sidebarVisible) {
                    toggleSidebar();
                }
            }
        }

        // Load a specific question
        function loadQuestion(categoryId, questionId) {
            currentCategoryId = categoryId;
            currentQuestionId = questionId;

            const category = interviewData.categories.find(c => c.id === categoryId);
            const question = category.questions.find(q => q.id === questionId);

            // Update active states in sidebar
            renderSidebar();

            // Update question header
            document.getElementById('questionTitle').textContent = question.question;
            document.getElementById('categoryBadge').textContent = category.name;

            // Render question content
            renderQuestionContent(question);
        }

        // Render question content
        function renderQuestionContent(question) {
            const contentArea = document.getElementById('questionContent');
            
            const suggestedCounter = getCounter(question.id, 'suggested');
            const bulletCounter = getCounter(question.id, 'bullet');

            contentArea.innerHTML = `
                <!-- Suggested Answer Section -->
                <div class="answer-section">
                    <div class="answer-header" onclick="toggleAnswer('suggested-${question.id}')">
                        <h3>ðŸ“ Suggested Answer</h3>
                        <div class="answer-controls">
                            <div class="counter">
                                <span>Practice:</span>
                                <span class="counter-value" id="suggested-counter-${question.id}">${suggestedCounter}</span>
                                <button class="counter-btn" onclick="incrementCounter(${question.id}, 'suggested', event)">+</button>
                            </div>
                            <button class="toggle-btn">Show</button>
                        </div>
                    </div>
                    <div class="answer-content" id="suggested-${question.id}">
                        <p>${question.suggestedAnswer}</p>
                    </div>
                </div>

                <!-- Bullet Points Section -->
                <div class="answer-section">
                    <div class="answer-header" onclick="toggleAnswer('bullet-${question.id}')">
                        <h3>ðŸŽ¯ Bullet Point Answer</h3>
                        <div class="answer-controls">
                            <div class="counter">
                                <span>Practice:</span>
                                <span class="counter-value" id="bullet-counter-${question.id}">${bulletCounter}</span>
                                <button class="counter-btn" onclick="incrementCounter(${question.id}, 'bullet', event)">+</button>
                            </div>
                            <button class="toggle-btn">Show</button>
                        </div>
                    </div>
                    <div class="answer-content" id="bullet-${question.id}">
                        <ul>
                            ${question.bulletPoints.map(point => `<li>${point}</li>`).join('')}
                        </ul>
                    </div>
                </div>

                <!-- Key Concepts Section -->
                <div class="key-concepts">
                    <h3>ðŸ’¡ Key Concepts</h3>
                    <div class="concept-buttons">
                        ${question.keyConcepts.map((concept, index) => 
                            `<button class="concept-btn" onclick='showConcept(${JSON.stringify(concept).replace(/'/g, "&apos;")})'>${concept.name}</button>`
                        ).join('')}
                    </div>
                </div>

                <!-- Navigation -->
                <div class="navigation">
                    <button class="nav-btn" onclick="navigateQuestion(-1)" id="prevBtn">
                        â† Previous
                    </button>
                    <button class="nav-btn" onclick="navigateQuestion(1)" id="nextBtn">
                        Next â†’
                    </button>
                </div>
            `;

            updateNavigationButtons();
        }

        // Toggle answer visibility
        function toggleAnswer(answerId) {
            const answerContent = document.getElementById(answerId);
            const toggleBtn = event.currentTarget.querySelector('.toggle-btn');
            
            answerContent.classList.toggle('visible');
            toggleBtn.textContent = answerContent.classList.contains('visible') ? 'Hide' : 'Show';
        }

        // Get counter from localStorage
        function getCounter(questionId, type) {
            const key = `counter-${questionId}-${type}`;
            return parseInt(localStorage.getItem(key) || '0');
        }

        // Increment counter
        function incrementCounter(questionId, type, event) {
            event.stopPropagation();
            const key = `counter-${questionId}-${type}`;
            const currentValue = getCounter(questionId, type);
            const newValue = currentValue + 1;
            localStorage.setItem(key, newValue.toString());
            
            document.getElementById(`${type}-counter-${questionId}`).textContent = newValue;
            
            // Update sidebar if visible
            if (!sidebarVisible) {
                renderSidebar();
            }
        }

        // Show concept modal
        function showConcept(concept) {
            const modal = document.getElementById('conceptModal');
            document.getElementById('conceptTitle').textContent = concept.name;
            document.getElementById('conceptBody').innerHTML = `<p>${concept.explanation}</p>`;
            modal.classList.add('active');
        }

        // Close modal
        function closeModal() {
            document.getElementById('conceptModal').classList.remove('active');
        }

        // Close modal when clicking outside
        window.onclick = function(event) {
            const modal = document.getElementById('conceptModal');
            if (event.target === modal) {
                closeModal();
            }
        }

        // Navigate between questions (across all questions, not per category)
        function navigateQuestion(direction) {
            const currentIndex = allQuestions.findIndex(q => q.id === currentQuestionId);
            const newIndex = currentIndex + direction;

            if (newIndex >= 0 && newIndex < allQuestions.length) {
                const newQuestion = allQuestions[newIndex];
                loadQuestion(newQuestion.categoryId, newQuestion.id);
            }

            updateNavigationButtons();
        }

        // Update navigation buttons
        function updateNavigationButtons() {
            const currentIndex = allQuestions.findIndex(q => q.id === currentQuestionId);

            const prevBtn = document.getElementById('prevBtn');
            const nextBtn = document.getElementById('nextBtn');

            // Disable previous button if at first question
            prevBtn.disabled = currentIndex === 0;

            // Disable next button if at last question
            nextBtn.disabled = currentIndex === allQuestions.length - 1;
        }

        // Initialize on page load
        window.onload = init;
    </script>
</body>
</html>
